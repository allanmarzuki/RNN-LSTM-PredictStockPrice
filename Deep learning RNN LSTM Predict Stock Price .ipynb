{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lawir\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\lawir\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\lawir\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\lawir\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\lawir\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\lawir\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\lawir\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\lawir\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\lawir\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\lawir\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\lawir\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\lawir\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(314)\n",
    "tf.random.set_random_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, \n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 59 (that is 50+10-1) length\n",
    "    # this last_sequence will be used to predict in future dates that are not available in the dataset\n",
    "    last_sequence = list(sequences) + list(last_sequence)\n",
    "    # shift the last sequence by -1\n",
    "    last_sequence = np.array(pd.DataFrame(last_sequence).shift(-1).dropna())\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    # reshape X to fit the neural network\n",
    "    X = X.reshape((X.shape[0], X.shape[2], X.shape[1]))\n",
    "    # split the dataset\n",
    "    result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, test_size=test_size, shuffle=shuffle)\n",
    "    # return the result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# panjang sequence\n",
    "N_STEPS = 100\n",
    "# jangka waktu perkiraan, hitungan hari\n",
    "LOOKUP_STEP = 1\n",
    "# rasio data test\n",
    "TEST_SIZE = 0.2\n",
    "# features yang dipake\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 3\n",
    "# LSTM cell, pake model lstm, bisa diganti\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout, rasio dropout neuron yang gk efektif\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss -> loss function, bisa diganti mse atau yang lainnya\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\" #optimizer bisa diganti pake sgd atau yang lain\n",
    "BATCH_SIZE = 64 #rasio batch\n",
    "EPOCHS = 400 #epoch, makin banyak makin bagus tapi lama\n",
    "# Apple stock market\n",
    "ticker = \"AAPL\" #data real yang dipake data penjualan produk apple inc, bundle dengan yahoo finance\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat folder buat simpen hasil dan logs training data\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lawir\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 7868 samples, validate on 1968 samples\n",
      "WARNING:tensorflow:From C:\\Users\\lawir\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0211\n",
      "Epoch 00001: val_loss improved from inf to 0.00037, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 0.0012 - mean_absolute_error: 0.0211 - val_loss: 3.7315e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 2/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 7.0916e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 00002: val_loss did not improve from 0.00037\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 7.0583e-04 - mean_absolute_error: 0.0170 - val_loss: 4.4757e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 3/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 5.5956e-04 - mean_absolute_error: 0.0150\n",
      "Epoch 00003: val_loss did not improve from 0.00037\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 5.5963e-04 - mean_absolute_error: 0.0150 - val_loss: 4.2734e-04 - val_mean_absolute_error: 0.0137\n",
      "Epoch 4/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 5.2640e-04 - mean_absolute_error: 0.0149\n",
      "Epoch 00004: val_loss did not improve from 0.00037\n",
      "7868/7868 [==============================] - 12s 1ms/sample - loss: 5.2680e-04 - mean_absolute_error: 0.0149 - val_loss: 7.9011e-04 - val_mean_absolute_error: 0.0204\n",
      "Epoch 5/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 4.3114e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 00005: val_loss improved from 0.00037 to 0.00025, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 4.2985e-04 - mean_absolute_error: 0.0139 - val_loss: 2.5488e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 6/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 3.6664e-04 - mean_absolute_error: 0.0128\n",
      "Epoch 00006: val_loss improved from 0.00025 to 0.00018, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 3.6893e-04 - mean_absolute_error: 0.0128 - val_loss: 1.7929e-04 - val_mean_absolute_error: 0.0093\n",
      "Epoch 7/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 4.1955e-04 - mean_absolute_error: 0.0136\n",
      "Epoch 00007: val_loss did not improve from 0.00018\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 4.1999e-04 - mean_absolute_error: 0.0136 - val_loss: 2.2430e-04 - val_mean_absolute_error: 0.0100\n",
      "Epoch 8/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 2.9227e-04 - mean_absolute_error: 0.0121\n",
      "Epoch 00008: val_loss did not improve from 0.00018\n",
      "7868/7868 [==============================] - 12s 1ms/sample - loss: 2.9205e-04 - mean_absolute_error: 0.0121 - val_loss: 2.6364e-04 - val_mean_absolute_error: 0.0089\n",
      "Epoch 9/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 2.8251e-04 - mean_absolute_error: 0.0117\n",
      "Epoch 00009: val_loss did not improve from 0.00018\n",
      "7868/7868 [==============================] - 12s 1ms/sample - loss: 2.8278e-04 - mean_absolute_error: 0.0117 - val_loss: 2.1068e-04 - val_mean_absolute_error: 0.0086\n",
      "Epoch 10/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 2.9600e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00010: val_loss improved from 0.00018 to 0.00008, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 2.9514e-04 - mean_absolute_error: 0.0119 - val_loss: 7.7932e-05 - val_mean_absolute_error: 0.0071\n",
      "Epoch 11/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 2.4967e-04 - mean_absolute_error: 0.0115\n",
      "Epoch 00011: val_loss did not improve from 0.00008\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 2.5060e-04 - mean_absolute_error: 0.0115 - val_loss: 1.8991e-04 - val_mean_absolute_error: 0.0121\n",
      "Epoch 12/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 2.6463e-04 - mean_absolute_error: 0.0116- ETA: 2s - loss: 2.6644e-04 - mean_ab\n",
      "Epoch 00012: val_loss did not improve from 0.00008\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 2.6648e-04 - mean_absolute_error: 0.0116 - val_loss: 9.1264e-05 - val_mean_absolute_error: 0.0088\n",
      "Epoch 13/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 2.8220e-04 - mean_absolute_error: 0.0119- ETA: 8s - loss: 2.738\n",
      "Epoch 00013: val_loss improved from 0.00008 to 0.00006, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 12s 1ms/sample - loss: 2.8263e-04 - mean_absolute_error: 0.0119 - val_loss: 6.2509e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 14/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 2.2707e-04 - mean_absolute_error: 0.0109- ETA: 5s - loss: 2.5819e-04 - mean_absolute_error: 0. - ETA: 4s \n",
      "Epoch 00014: val_loss did not improve from 0.00006\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 2.2795e-04 - mean_absolute_error: 0.0110 - val_loss: 7.3238e-05 - val_mean_absolute_error: 0.0064\n",
      "Epoch 15/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 2.3329e-04 - mean_absolute_error: 0.0114\n",
      "Epoch 00015: val_loss did not improve from 0.00006\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 2.3283e-04 - mean_absolute_error: 0.0114 - val_loss: 7.1961e-05 - val_mean_absolute_error: 0.0067\n",
      "Epoch 16/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.8646e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00016: val_loss improved from 0.00006 to 0.00004, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.8534e-04 - mean_absolute_error: 0.0103 - val_loss: 3.8760e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 17/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.9882e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00017: val_loss did not improve from 0.00004\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.9887e-04 - mean_absolute_error: 0.0107 - val_loss: 6.4578e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 18/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 2.0975e-04 - mean_absolute_error: 0.0108- ETA: 2s - loss: 2.1678e-04 - mean_absolute_e - ETA: 0s - loss: 2.1478e-04 - mean_absolute_error\n",
      "Epoch 00018: val_loss did not improve from 0.00004\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 2.0945e-04 - mean_absolute_error: 0.0108 - val_loss: 4.6848e-05 - val_mean_absolute_error: 0.0068\n",
      "Epoch 19/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.8326e-04 - mean_absolute_error: 0.0103- ETA: 0s - loss: 1.8248e-04 - mean_absolute_error: \n",
      "Epoch 00019: val_loss improved from 0.00004 to 0.00003, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.8370e-04 - mean_absolute_error: 0.0104 - val_loss: 3.3253e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 20/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.9034e-04 - mean_absolute_error: 0.0102\n",
      "Epoch 00020: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.8955e-04 - mean_absolute_error: 0.0102 - val_loss: 4.3692e-05 - val_mean_absolute_error: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 2.0449e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 00021: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 2.0488e-04 - mean_absolute_error: 0.0111 - val_loss: 6.7453e-05 - val_mean_absolute_error: 0.0048\n",
      "Epoch 22/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.7715e-04 - mean_absolute_error: 0.0102\n",
      "Epoch 00022: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.7667e-04 - mean_absolute_error: 0.0102 - val_loss: 9.8429e-05 - val_mean_absolute_error: 0.0078\n",
      "Epoch 23/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.7301e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00023: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 1.7246e-04 - mean_absolute_error: 0.0103 - val_loss: 8.6978e-05 - val_mean_absolute_error: 0.0072\n",
      "Epoch 24/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.9066e-04 - mean_absolute_error: 0.0108- ETA: 2s - loss: 1.8881e-04 -\n",
      "Epoch 00024: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 1.9122e-04 - mean_absolute_error: 0.0108 - val_loss: 4.3792e-05 - val_mean_absolute_error: 0.0069\n",
      "Epoch 25/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.6425e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00025: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 1.6375e-04 - mean_absolute_error: 0.0104 - val_loss: 5.1502e-05 - val_mean_absolute_error: 0.0063\n",
      "Epoch 26/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4520e-04 - mean_absolute_error: 0.0097\n",
      "Epoch 00026: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 1.4504e-04 - mean_absolute_error: 0.0097 - val_loss: 4.2818e-05 - val_mean_absolute_error: 0.0050\n",
      "Epoch 27/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 2.1538e-04 - mean_absolute_error: 0.0115\n",
      "Epoch 00027: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 2.1426e-04 - mean_absolute_error: 0.0115 - val_loss: 7.8632e-05 - val_mean_absolute_error: 0.0066\n",
      "Epoch 28/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.6657e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00028: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 12s 1ms/sample - loss: 1.6660e-04 - mean_absolute_error: 0.0105 - val_loss: 4.0581e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 29/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4052e-04 - mean_absolute_error: 0.0096\n",
      "Epoch 00029: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.4108e-04 - mean_absolute_error: 0.0096 - val_loss: 4.3662e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 30/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4657e-04 - mean_absolute_error: 0.0096\n",
      "Epoch 00030: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.4709e-04 - mean_absolute_error: 0.0096 - val_loss: 7.2811e-05 - val_mean_absolute_error: 0.0064\n",
      "Epoch 31/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.6112e-04 - mean_absolute_error: 0.0101\n",
      "Epoch 00031: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.6091e-04 - mean_absolute_error: 0.0101 - val_loss: 7.6433e-05 - val_mean_absolute_error: 0.0052\n",
      "Epoch 32/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.7112e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00032: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.7039e-04 - mean_absolute_error: 0.0104 - val_loss: 6.9298e-05 - val_mean_absolute_error: 0.0061\n",
      "Epoch 33/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.5115e-04 - mean_absolute_error: 0.0097\n",
      "Epoch 00033: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.5080e-04 - mean_absolute_error: 0.0097 - val_loss: 6.8014e-05 - val_mean_absolute_error: 0.0057\n",
      "Epoch 34/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.7100e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00034: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.7049e-04 - mean_absolute_error: 0.0107 - val_loss: 7.0911e-05 - val_mean_absolute_error: 0.0077\n",
      "Epoch 35/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4344e-04 - mean_absolute_error: 0.0097\n",
      "Epoch 00035: val_loss did not improve from 0.00003\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.4270e-04 - mean_absolute_error: 0.0097 - val_loss: 7.7035e-05 - val_mean_absolute_error: 0.0079\n",
      "Epoch 36/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.5213e-04 - mean_absolute_error: 0.0100\n",
      "Epoch 00036: val_loss improved from 0.00003 to 0.00003, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.5269e-04 - mean_absolute_error: 0.0101 - val_loss: 2.6680e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 37/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4223e-04 - mean_absolute_error: 0.0100\n",
      "Epoch 00037: val_loss improved from 0.00003 to 0.00002, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.4219e-04 - mean_absolute_error: 0.0100 - val_loss: 2.4151e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 38/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4595e-04 - mean_absolute_error: 0.0099\n",
      "Epoch 00038: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.4609e-04 - mean_absolute_error: 0.0099 - val_loss: 3.6087e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 39/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.9796e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 00039: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 1ms/sample - loss: 1.9792e-04 - mean_absolute_error: 0.0116 - val_loss: 2.9369e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 40/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.5701e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00040: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.5603e-04 - mean_absolute_error: 0.0103 - val_loss: 5.1103e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 41/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.5726e-04 - mean_absolute_error: 0.0103- ETA: 0s - loss: 1.5772e-04 - mean_absolute_error: 0\n",
      "Epoch 00041: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.5753e-04 - mean_absolute_error: 0.0103 - val_loss: 5.5767e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 42/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4786e-04 - mean_absolute_error: 0.0098\n",
      "Epoch 00042: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.4730e-04 - mean_absolute_error: 0.0098 - val_loss: 2.8827e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 43/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2610e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00043: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.2616e-04 - mean_absolute_error: 0.0094 - val_loss: 4.2059e-05 - val_mean_absolute_error: 0.0061\n",
      "Epoch 44/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1800e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00044: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.1783e-04 - mean_absolute_error: 0.0089 - val_loss: 5.3477e-05 - val_mean_absolute_error: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.5813e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00045: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 1.5801e-04 - mean_absolute_error: 0.0104 - val_loss: 1.1547e-04 - val_mean_absolute_error: 0.0084\n",
      "Epoch 46/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2767e-04 - mean_absolute_error: 0.0094\n",
      "Epoch 00046: val_loss improved from 0.00002 to 0.00002, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 1.2745e-04 - mean_absolute_error: 0.0094 - val_loss: 2.3180e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 47/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1836e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00047: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 1ms/sample - loss: 1.1816e-04 - mean_absolute_error: 0.0090 - val_loss: 5.9414e-05 - val_mean_absolute_error: 0.0087\n",
      "Epoch 48/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.5309e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 00048: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 1.5275e-04 - mean_absolute_error: 0.0109 - val_loss: 7.1795e-05 - val_mean_absolute_error: 0.0085\n",
      "Epoch 49/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4632e-04 - mean_absolute_error: 0.0098- ETA: 3s - loss: \n",
      "Epoch 00049: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 1.4852e-04 - mean_absolute_error: 0.0099 - val_loss: 7.7326e-05 - val_mean_absolute_error: 0.0108\n",
      "Epoch 50/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.8878e-04 - mean_absolute_error: 0.0115- ETA: 5s - loss: 1.8802e-04 - mean_absolute_error: 0\n",
      "Epoch 00050: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 1ms/sample - loss: 1.8854e-04 - mean_absolute_error: 0.0115 - val_loss: 1.1062e-04 - val_mean_absolute_error: 0.0138\n",
      "Epoch 51/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4272e-04 - mean_absolute_error: 0.0100\n",
      "Epoch 00051: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 1.4426e-04 - mean_absolute_error: 0.0101 - val_loss: 5.1074e-05 - val_mean_absolute_error: 0.0077\n",
      "Epoch 52/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.5623e-04 - mean_absolute_error: 0.0102\n",
      "Epoch 00052: val_loss improved from 0.00002 to 0.00002, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 1.5734e-04 - mean_absolute_error: 0.0102 - val_loss: 2.1443e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 53/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2748e-04 - mean_absolute_error: 0.0092- ETA: 0s - loss: 1.2577e-04 - mean_absolute_error: 0. - ETA: 0s - loss: 1.2667e-04 - mean_absolute_error: 0.009\n",
      "Epoch 00053: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.2768e-04 - mean_absolute_error: 0.0092 - val_loss: 3.3485e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 54/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2291e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00054: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.2254e-04 - mean_absolute_error: 0.0091 - val_loss: 8.2801e-05 - val_mean_absolute_error: 0.0101\n",
      "Epoch 55/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4205e-04 - mean_absolute_error: 0.0098- ETA: 6s - loss: 1.4429e-04 - mean_a - ETA: 4s - loss: 1.4680e-04 - mean_absolute_error:  - ETA: 3s - lo\n",
      "Epoch 00055: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.4183e-04 - mean_absolute_error: 0.0098 - val_loss: 3.5237e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 56/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3676e-04 - mean_absolute_error: 0.0097- ETA: 2s - loss: 1.4992e-04\n",
      "Epoch 00056: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 1.3650e-04 - mean_absolute_error: 0.0097 - val_loss: 4.5498e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 57/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2700e-04 - mean_absolute_error: 0.0092- ETA:\n",
      "Epoch 00057: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.2666e-04 - mean_absolute_error: 0.0092 - val_loss: 3.9138e-05 - val_mean_absolute_error: 0.0048\n",
      "Epoch 58/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3187e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00058: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.3172e-04 - mean_absolute_error: 0.0092 - val_loss: 3.1182e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 59/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4108e-04 - mean_absolute_error: 0.009 - ETA: 0s - loss: 1.4043e-04 - mean_absolute_error: 0.0096\n",
      "Epoch 00059: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.4041e-04 - mean_absolute_error: 0.0096 - val_loss: 4.3931e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 60/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2367e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00060: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 1.2347e-04 - mean_absolute_error: 0.0092 - val_loss: 4.4285e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 61/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4650e-04 - mean_absolute_error: 0.0097\n",
      "Epoch 00061: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 1ms/sample - loss: 1.4569e-04 - mean_absolute_error: 0.0097 - val_loss: 2.0225e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 62/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.5290e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00062: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.5209e-04 - mean_absolute_error: 0.0104 - val_loss: 5.1763e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 63/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2947e-04 - mean_absolute_error: 0.0092- ETA: 0s - loss: 1.2954e-04 - mean_absolute_error: 0.0\n",
      "Epoch 00063: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.2952e-04 - mean_absolute_error: 0.0092 - val_loss: 3.8368e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 64/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3493e-04 - mean_absolute_error: 0.0097- ETA: 3s - loss: 1.3283\n",
      "Epoch 00064: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.3494e-04 - mean_absolute_error: 0.0097 - val_loss: 5.8511e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 65/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2472e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00065: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.2404e-04 - mean_absolute_error: 0.0091 - val_loss: 4.5079e-05 - val_mean_absolute_error: 0.0052\n",
      "Epoch 66/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2629e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00066: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.2767e-04 - mean_absolute_error: 0.0093 - val_loss: 6.5118e-05 - val_mean_absolute_error: 0.0090\n",
      "Epoch 67/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4992e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00067: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.4947e-04 - mean_absolute_error: 0.0103 - val_loss: 5.8170e-05 - val_mean_absolute_error: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.5206e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 00068: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 2ms/sample - loss: 1.5230e-04 - mean_absolute_error: 0.0103 - val_loss: 7.1248e-05 - val_mean_absolute_error: 0.0100\n",
      "Epoch 69/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.5879e-04 - mean_absolute_error: 0.0102\n",
      "Epoch 00069: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 19s 2ms/sample - loss: 1.5873e-04 - mean_absolute_error: 0.0102 - val_loss: 4.9069e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 70/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4250e-04 - mean_absolute_error: 0.0100\n",
      "Epoch 00070: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 2ms/sample - loss: 1.4177e-04 - mean_absolute_error: 0.0099 - val_loss: 6.0511e-05 - val_mean_absolute_error: 0.0070\n",
      "Epoch 71/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4013e-04 - mean_absolute_error: 0.0096\n",
      "Epoch 00071: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.4104e-04 - mean_absolute_error: 0.0096 - val_loss: 3.5944e-05 - val_mean_absolute_error: 0.0052\n",
      "Epoch 72/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4203e-04 - mean_absolute_error: 0.0100\n",
      "Epoch 00072: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.4139e-04 - mean_absolute_error: 0.0100 - val_loss: 3.6098e-05 - val_mean_absolute_error: 0.0068\n",
      "Epoch 73/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.6287e-04 - mean_absolute_error: 0.0108\n",
      "Epoch 00073: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.6245e-04 - mean_absolute_error: 0.0107 - val_loss: 4.2670e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 74/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2578e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00074: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 1.2787e-04 - mean_absolute_error: 0.0091 - val_loss: 2.9530e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 75/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2528e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00075: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 11s 1ms/sample - loss: 1.2529e-04 - mean_absolute_error: 0.0093 - val_loss: 4.7465e-05 - val_mean_absolute_error: 0.0048\n",
      "Epoch 76/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3228e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00076: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 12s 1ms/sample - loss: 1.3227e-04 - mean_absolute_error: 0.0092 - val_loss: 6.8799e-05 - val_mean_absolute_error: 0.0052\n",
      "Epoch 77/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0702e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00077: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.0656e-04 - mean_absolute_error: 0.0087 - val_loss: 2.3629e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 78/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3500e-04 - mean_absolute_error: 0.0096\n",
      "Epoch 00078: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.3619e-04 - mean_absolute_error: 0.0096 - val_loss: 7.0179e-05 - val_mean_absolute_error: 0.0076\n",
      "Epoch 79/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3786e-04 - mean_absolute_error: 0.0097\n",
      "Epoch 00079: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 1.3825e-04 - mean_absolute_error: 0.0097 - val_loss: 2.7924e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 80/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3274e-04 - mean_absolute_error: 0.0095\n",
      "Epoch 00080: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.3355e-04 - mean_absolute_error: 0.0096 - val_loss: 9.9816e-05 - val_mean_absolute_error: 0.0086\n",
      "Epoch 81/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.7113e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00081: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.7422e-04 - mean_absolute_error: 0.0105 - val_loss: 7.5150e-05 - val_mean_absolute_error: 0.0062\n",
      "Epoch 82/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4372e-04 - mean_absolute_error: 0.0098\n",
      "Epoch 00082: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.4318e-04 - mean_absolute_error: 0.0098 - val_loss: 3.3121e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 83/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4004e-04 - mean_absolute_error: 0.0095\n",
      "Epoch 00083: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.3951e-04 - mean_absolute_error: 0.0095 - val_loss: 3.4970e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 84/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4079e-04 - mean_absolute_error: 0.0098\n",
      "Epoch 00084: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.4028e-04 - mean_absolute_error: 0.0098 - val_loss: 2.7480e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 85/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3484e-04 - mean_absolute_error: 0.0096- ETA: 1s - loss: 1.3672e-04 - mean_absolu\n",
      "Epoch 00085: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.3465e-04 - mean_absolute_error: 0.0096 - val_loss: 3.1467e-05 - val_mean_absolute_error: 0.0061\n",
      "Epoch 86/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2582e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00086: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.2586e-04 - mean_absolute_error: 0.0093 - val_loss: 2.2080e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 87/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2917e-04 - mean_absolute_error: 0.0100\n",
      "Epoch 00087: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.2886e-04 - mean_absolute_error: 0.0100 - val_loss: 5.3627e-05 - val_mean_absolute_error: 0.0074\n",
      "Epoch 88/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3711e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00088: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.3672e-04 - mean_absolute_error: 0.0093 - val_loss: 1.2372e-04 - val_mean_absolute_error: 0.0081\n",
      "Epoch 89/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4523e-04 - mean_absolute_error: 0.0101\n",
      "Epoch 00089: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.4683e-04 - mean_absolute_error: 0.0101 - val_loss: 1.4531e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 90/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3220e-04 - mean_absolute_error: 0.0094\n",
      "Epoch 00090: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.3215e-04 - mean_absolute_error: 0.0094 - val_loss: 6.0257e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 91/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3345e-04 - mean_absolute_error: 0.0095\n",
      "Epoch 00091: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.3277e-04 - mean_absolute_error: 0.0095 - val_loss: 2.4802e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 92/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1788e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00092: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.1822e-04 - mean_absolute_error: 0.0090 - val_loss: 6.6194e-05 - val_mean_absolute_error: 0.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4114e-04 - mean_absolute_error: 0.0101\n",
      "Epoch 00093: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.4129e-04 - mean_absolute_error: 0.0101 - val_loss: 4.0567e-05 - val_mean_absolute_error: 0.0073\n",
      "Epoch 94/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.5103e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 00094: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.5153e-04 - mean_absolute_error: 0.0105 - val_loss: 3.1096e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 95/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3131e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00095: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.3068e-04 - mean_absolute_error: 0.0092 - val_loss: 5.2387e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 96/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3677e-04 - mean_absolute_error: 0.0097\n",
      "Epoch 00096: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.3750e-04 - mean_absolute_error: 0.0097 - val_loss: 4.8301e-05 - val_mean_absolute_error: 0.0068\n",
      "Epoch 97/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1671e-04 - mean_absolute_error: 0.0088-\n",
      "Epoch 00097: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.1951e-04 - mean_absolute_error: 0.0088 - val_loss: 5.1858e-05 - val_mean_absolute_error: 0.0078\n",
      "Epoch 98/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1463e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00098: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.1408e-04 - mean_absolute_error: 0.0089 - val_loss: 3.7414e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 99/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3813e-04 - mean_absolute_error: 0.0094\n",
      "Epoch 00099: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.3822e-04 - mean_absolute_error: 0.0094 - val_loss: 2.5884e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 100/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2391e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00100: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.2331e-04 - mean_absolute_error: 0.0092 - val_loss: 2.6464e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 101/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3320e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00101: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.3275e-04 - mean_absolute_error: 0.0093 - val_loss: 2.8372e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 102/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2200e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00102: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.2220e-04 - mean_absolute_error: 0.0090 - val_loss: 4.1909e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 103/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0266e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00103: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.0302e-04 - mean_absolute_error: 0.0085 - val_loss: 2.8343e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 104/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2246e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00104: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.2235e-04 - mean_absolute_error: 0.0091 - val_loss: 1.4498e-04 - val_mean_absolute_error: 0.0101\n",
      "Epoch 105/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.5444e-04 - mean_absolute_error: 0.0099\n",
      "Epoch 00105: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.5462e-04 - mean_absolute_error: 0.0099 - val_loss: 8.5753e-05 - val_mean_absolute_error: 0.0079\n",
      "Epoch 106/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2402e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00106: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.2383e-04 - mean_absolute_error: 0.0091 - val_loss: 4.7324e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 107/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3110e-04 - mean_absolute_error: 0.0095\n",
      "Epoch 00107: val_loss improved from 0.00002 to 0.00002, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.3162e-04 - mean_absolute_error: 0.0095 - val_loss: 2.1166e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 108/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1338e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00108: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.1590e-04 - mean_absolute_error: 0.0088 - val_loss: 1.0344e-04 - val_mean_absolute_error: 0.0077\n",
      "Epoch 109/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0879e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00109: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.0846e-04 - mean_absolute_error: 0.0089 - val_loss: 3.4253e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 110/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3458e-04 - mean_absolute_error: 0.0095\n",
      "Epoch 00110: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.3504e-04 - mean_absolute_error: 0.0095 - val_loss: 1.5713e-04 - val_mean_absolute_error: 0.0091\n",
      "Epoch 111/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2053e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00111: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.2039e-04 - mean_absolute_error: 0.0093 - val_loss: 7.4932e-05 - val_mean_absolute_error: 0.0064\n",
      "Epoch 112/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0487e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00112: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.0436e-04 - mean_absolute_error: 0.0084 - val_loss: 2.1891e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 113/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2780e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00113: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.2799e-04 - mean_absolute_error: 0.0093 - val_loss: 2.7067e-05 - val_mean_absolute_error: 0.0035\n",
      "Epoch 114/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2976e-04 - mean_absolute_error: 0.0094\n",
      "Epoch 00114: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.2961e-04 - mean_absolute_error: 0.0094 - val_loss: 3.9341e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 115/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2477e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00115: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.2455e-04 - mean_absolute_error: 0.0092 - val_loss: 2.1199e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 116/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1583e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00116: val_loss improved from 0.00002 to 0.00002, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.1751e-04 - mean_absolute_error: 0.0090 - val_loss: 1.8616e-05 - val_mean_absolute_error: 0.0029\n",
      "Epoch 117/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1919e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00117: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.1870e-04 - mean_absolute_error: 0.0092 - val_loss: 1.9069e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 118/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1633e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00118: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.1577e-04 - mean_absolute_error: 0.0089 - val_loss: 3.2445e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 119/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3359e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00119: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.3396e-04 - mean_absolute_error: 0.0093 - val_loss: 6.9297e-05 - val_mean_absolute_error: 0.0066\n",
      "Epoch 120/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2290e-04 - mean_absolute_error: 0.0094\n",
      "Epoch 00120: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.2219e-04 - mean_absolute_error: 0.0094 - val_loss: 3.8472e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 121/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3312e-04 - mean_absolute_error: 0.0096\n",
      "Epoch 00121: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.3320e-04 - mean_absolute_error: 0.0096 - val_loss: 2.2263e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 122/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1022e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00122: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.1080e-04 - mean_absolute_error: 0.0086 - val_loss: 4.9928e-05 - val_mean_absolute_error: 0.0057\n",
      "Epoch 123/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2282e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00123: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.2301e-04 - mean_absolute_error: 0.0091 - val_loss: 2.4362e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 124/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2464e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00124: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.2644e-04 - mean_absolute_error: 0.0092 - val_loss: 4.5272e-05 - val_mean_absolute_error: 0.0048\n",
      "Epoch 125/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2167e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00125: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.2102e-04 - mean_absolute_error: 0.0092 - val_loss: 6.5621e-05 - val_mean_absolute_error: 0.0088\n",
      "Epoch 126/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1603e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00126: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.1635e-04 - mean_absolute_error: 0.0091 - val_loss: 4.3178e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 127/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3087e-04 - mean_absolute_error: 0.0094- ETA: 5s - loss:\n",
      "Epoch 00127: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 1.3170e-04 - mean_absolute_error: 0.0095 - val_loss: 3.7903e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 128/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1689e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00128: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.1675e-04 - mean_absolute_error: 0.0091 - val_loss: 3.3999e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 129/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2386e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00129: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.2441e-04 - mean_absolute_error: 0.0091 - val_loss: 5.7071e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 130/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1619e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00130: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.1594e-04 - mean_absolute_error: 0.0091 - val_loss: 4.3830e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 131/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1784e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00131: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 13s 2ms/sample - loss: 1.1756e-04 - mean_absolute_error: 0.0090 - val_loss: 3.6361e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 132/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2481e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00132: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.2564e-04 - mean_absolute_error: 0.0091 - val_loss: 6.1254e-05 - val_mean_absolute_error: 0.0066\n",
      "Epoch 133/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1712e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00133: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.1668e-04 - mean_absolute_error: 0.0089 - val_loss: 2.7147e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 134/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1016e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00134: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.0987e-04 - mean_absolute_error: 0.0087 - val_loss: 4.3747e-05 - val_mean_absolute_error: 0.0050\n",
      "Epoch 135/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0886e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00135: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.1003e-04 - mean_absolute_error: 0.0086 - val_loss: 4.2542e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 136/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3454e-04 - mean_absolute_error: 0.0098\n",
      "Epoch 00136: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.3501e-04 - mean_absolute_error: 0.0098 - val_loss: 4.4110e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 137/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1289e-04 - mean_absolute_error: 0.0088- ETA: 1s - loss: 1.1237e-04 - mean_absolut\n",
      "Epoch 00137: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.1274e-04 - mean_absolute_error: 0.0088 - val_loss: 7.5984e-05 - val_mean_absolute_error: 0.0068\n",
      "Epoch 138/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2169e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00138: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.2264e-04 - mean_absolute_error: 0.0089 - val_loss: 2.4591e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 139/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0972e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00139: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.1116e-04 - mean_absolute_error: 0.0089 - val_loss: 8.4224e-05 - val_mean_absolute_error: 0.0100\n",
      "Epoch 140/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2253e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00140: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.2278e-04 - mean_absolute_error: 0.0090 - val_loss: 2.9957e-05 - val_mean_absolute_error: 0.0047\n",
      "Epoch 141/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1019e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00141: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.0994e-04 - mean_absolute_error: 0.0089 - val_loss: 7.3523e-05 - val_mean_absolute_error: 0.0069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2546e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00142: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.2543e-04 - mean_absolute_error: 0.0091 - val_loss: 2.2005e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 143/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2833e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00143: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.2911e-04 - mean_absolute_error: 0.0092 - val_loss: 3.5529e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 144/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0364e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00144: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.0404e-04 - mean_absolute_error: 0.0085 - val_loss: 2.3117e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 145/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1688e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00145: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.1631e-04 - mean_absolute_error: 0.0088 - val_loss: 2.4719e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 146/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0885e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00146: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.0880e-04 - mean_absolute_error: 0.0087 - val_loss: 5.2568e-05 - val_mean_absolute_error: 0.0079\n",
      "Epoch 147/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1789e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00147: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.1747e-04 - mean_absolute_error: 0.0091 - val_loss: 6.3775e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 148/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3114e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00148: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.3057e-04 - mean_absolute_error: 0.0091 - val_loss: 5.3370e-05 - val_mean_absolute_error: 0.0061\n",
      "Epoch 149/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1916e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00149: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.1922e-04 - mean_absolute_error: 0.0090 - val_loss: 6.5155e-05 - val_mean_absolute_error: 0.0048\n",
      "Epoch 150/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2430e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00150: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 14s 2ms/sample - loss: 1.2403e-04 - mean_absolute_error: 0.0090 - val_loss: 8.4892e-05 - val_mean_absolute_error: 0.0050\n",
      "Epoch 151/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2003e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00151: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.1953e-04 - mean_absolute_error: 0.0090 - val_loss: 6.8616e-05 - val_mean_absolute_error: 0.0085\n",
      "Epoch 152/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2020e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00152: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.2050e-04 - mean_absolute_error: 0.0090 - val_loss: 5.6847e-05 - val_mean_absolute_error: 0.0070\n",
      "Epoch 153/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0410e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00153: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.0416e-04 - mean_absolute_error: 0.0087 - val_loss: 2.8384e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 154/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3289e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00154: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.3232e-04 - mean_absolute_error: 0.0093 - val_loss: 6.4403e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 155/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1082e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00155: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.1014e-04 - mean_absolute_error: 0.0088 - val_loss: 4.1227e-05 - val_mean_absolute_error: 0.0047\n",
      "Epoch 156/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0908e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00156: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.0848e-04 - mean_absolute_error: 0.0087 - val_loss: 3.5405e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 157/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2572e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00157: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.2529e-04 - mean_absolute_error: 0.0091 - val_loss: 7.2839e-05 - val_mean_absolute_error: 0.0065\n",
      "Epoch 158/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1663e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00158: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.1656e-04 - mean_absolute_error: 0.0090 - val_loss: 4.6519e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 159/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.3976e-04 - mean_absolute_error: 0.0095\n",
      "Epoch 00159: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.4047e-04 - mean_absolute_error: 0.0096 - val_loss: 1.0527e-04 - val_mean_absolute_error: 0.0089\n",
      "Epoch 160/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1580e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00160: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.1581e-04 - mean_absolute_error: 0.0088 - val_loss: 3.5816e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 161/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2630e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00161: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.2564e-04 - mean_absolute_error: 0.0090 - val_loss: 4.8716e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 162/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2663e-04 - mean_absolute_error: 0.0094\n",
      "Epoch 00162: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.2596e-04 - mean_absolute_error: 0.0094 - val_loss: 2.8359e-05 - val_mean_absolute_error: 0.0047\n",
      "Epoch 163/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1383e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00163: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.1341e-04 - mean_absolute_error: 0.0089 - val_loss: 6.6906e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 164/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0772e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00164: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.0823e-04 - mean_absolute_error: 0.0085 - val_loss: 1.2620e-04 - val_mean_absolute_error: 0.0072\n",
      "Epoch 165/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1281e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00165: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.1282e-04 - mean_absolute_error: 0.0089 - val_loss: 5.4128e-05 - val_mean_absolute_error: 0.0070\n",
      "Epoch 166/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2305e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00166: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.2263e-04 - mean_absolute_error: 0.0091 - val_loss: 3.9130e-05 - val_mean_absolute_error: 0.0069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1283e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00167: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.1276e-04 - mean_absolute_error: 0.0088 - val_loss: 6.8231e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 168/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2196e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00168: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 15s 2ms/sample - loss: 1.2142e-04 - mean_absolute_error: 0.0088 - val_loss: 2.9474e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 169/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2711e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00169: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.2642e-04 - mean_absolute_error: 0.0091 - val_loss: 3.1675e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 170/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1344e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00170: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.1321e-04 - mean_absolute_error: 0.0088 - val_loss: 4.4083e-05 - val_mean_absolute_error: 0.0061\n",
      "Epoch 171/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0383e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00171: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.0395e-04 - mean_absolute_error: 0.0085 - val_loss: 2.0617e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 172/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2703e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00172: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.2651e-04 - mean_absolute_error: 0.0092 - val_loss: 6.7385e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 173/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2790e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00173: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.2824e-04 - mean_absolute_error: 0.0091 - val_loss: 7.4867e-05 - val_mean_absolute_error: 0.0080\n",
      "Epoch 174/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0658e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00174: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.0612e-04 - mean_absolute_error: 0.0085 - val_loss: 2.6527e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 175/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2273e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00175: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.2214e-04 - mean_absolute_error: 0.0093 - val_loss: 7.1336e-05 - val_mean_absolute_error: 0.0050\n",
      "Epoch 176/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0224e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00176: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.0217e-04 - mean_absolute_error: 0.0084 - val_loss: 4.0771e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 177/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1525e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00177: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.1696e-04 - mean_absolute_error: 0.0088 - val_loss: 4.0039e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 178/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1488e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00178: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.1492e-04 - mean_absolute_error: 0.0088 - val_loss: 4.3228e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 179/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0901e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00179: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.0885e-04 - mean_absolute_error: 0.0086 - val_loss: 3.8705e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 180/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0889e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00180: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.0869e-04 - mean_absolute_error: 0.0087 - val_loss: 3.1216e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 181/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0499e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00181: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.0571e-04 - mean_absolute_error: 0.0086 - val_loss: 4.0453e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 182/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.4080e-04 - mean_absolute_error: 0.0097\n",
      "Epoch 00182: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.4057e-04 - mean_absolute_error: 0.0097 - val_loss: 3.4085e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 183/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0358e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00183: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.0310e-04 - mean_absolute_error: 0.0085 - val_loss: 3.6538e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 184/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1387e-04 - mean_absolute_error: 0.0087- ETA: 3s - loss: 1.1941e-04\n",
      "Epoch 00184: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 16s 2ms/sample - loss: 1.1358e-04 - mean_absolute_error: 0.0087 - val_loss: 2.3099e-05 - val_mean_absolute_error: 0.0029\n",
      "Epoch 185/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2708e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00185: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.2695e-04 - mean_absolute_error: 0.0093 - val_loss: 3.0881e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 186/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2150e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00186: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.2190e-04 - mean_absolute_error: 0.0091 - val_loss: 3.6733e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 187/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.7949e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00187: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 9.7630e-05 - mean_absolute_error: 0.0084 - val_loss: 1.8786e-05 - val_mean_absolute_error: 0.0028\n",
      "Epoch 188/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1921e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00188: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.2108e-04 - mean_absolute_error: 0.0090 - val_loss: 3.2225e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 189/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0563e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00189: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.0559e-04 - mean_absolute_error: 0.0085 - val_loss: 4.5066e-05 - val_mean_absolute_error: 0.0048\n",
      "Epoch 190/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0095e-04 - mean_absolute_error: 0.0084- ETA: 8s - l - ETA: 3s - loss: 1.0465e-04 - mean_a\n",
      "Epoch 00190: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 19s 2ms/sample - loss: 1.0134e-04 - mean_absolute_error: 0.0084 - val_loss: 1.9680e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 191/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1300e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00191: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 1.1288e-04 - mean_absolute_error: 0.0087 - val_loss: 2.4975e-05 - val_mean_absolute_error: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0786e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00192: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.0842e-04 - mean_absolute_error: 0.0086 - val_loss: 4.9746e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 193/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2797e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00193: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.2741e-04 - mean_absolute_error: 0.0090 - val_loss: 2.4285e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 194/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0954e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00194: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.0921e-04 - mean_absolute_error: 0.0086 - val_loss: 2.5522e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 195/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0815e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00195: val_loss improved from 0.00002 to 0.00002, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 1.0826e-04 - mean_absolute_error: 0.0086 - val_loss: 1.6225e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 196/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0062e-04 - mean_absolute_error: 0.0085- ETA: 2s - loss: 1.0121e-04 - mean_absolu\n",
      "Epoch 00196: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.0031e-04 - mean_absolute_error: 0.0085 - val_loss: 2.3696e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 197/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.9913e-05 - mean_absolute_error: 0.0084\n",
      "Epoch 00197: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 9.9463e-05 - mean_absolute_error: 0.0084 - val_loss: 4.5365e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 198/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1803e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00198: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.1753e-04 - mean_absolute_error: 0.0090 - val_loss: 2.4845e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 199/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0555e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00199: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.0576e-04 - mean_absolute_error: 0.0086 - val_loss: 5.1855e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 200/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1114e-04 - mean_absolute_error: 0.0087- ETA: 2s - loss: 1.1006e-04 - mean_abs\n",
      "Epoch 00200: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.1068e-04 - mean_absolute_error: 0.0087 - val_loss: 5.4513e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 201/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.7253e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 00201: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 9.7399e-05 - mean_absolute_error: 0.0083 - val_loss: 2.2596e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 202/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1059e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00202: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.1125e-04 - mean_absolute_error: 0.0086 - val_loss: 3.1777e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 203/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1958e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00203: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 1.2088e-04 - mean_absolute_error: 0.0090 - val_loss: 3.2532e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 204/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0153e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00204: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.0178e-04 - mean_absolute_error: 0.0085 - val_loss: 4.1552e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 205/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0519e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00205: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.0708e-04 - mean_absolute_error: 0.0086 - val_loss: 2.8654e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 206/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0999e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00206: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 17s 2ms/sample - loss: 1.0966e-04 - mean_absolute_error: 0.0087 - val_loss: 2.4447e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 207/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1629e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00207: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 1.1613e-04 - mean_absolute_error: 0.0089 - val_loss: 4.1027e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 208/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1386e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00208: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 1.1370e-04 - mean_absolute_error: 0.0085 - val_loss: 2.5257e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 209/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0729e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00209: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 1.0691e-04 - mean_absolute_error: 0.0084 - val_loss: 3.3156e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 210/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0486e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00210: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 1.0535e-04 - mean_absolute_error: 0.0085 - val_loss: 4.6239e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 211/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2052e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00211: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 1.2038e-04 - mean_absolute_error: 0.0089 - val_loss: 2.5072e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 212/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.6967e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 00212: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 9.6534e-05 - mean_absolute_error: 0.0081 - val_loss: 2.0740e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 213/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0736e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00213: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 1.0755e-04 - mean_absolute_error: 0.0084 - val_loss: 6.2457e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 214/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.8587e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 00214: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 9.8685e-05 - mean_absolute_error: 0.0084 - val_loss: 1.8460e-05 - val_mean_absolute_error: 0.0029\n",
      "Epoch 215/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.3516e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 00215: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 9.3451e-05 - mean_absolute_error: 0.0082 - val_loss: 2.3149e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 216/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.6131e-05 - mean_absolute_error: 0.0084- ETA: 2s - loss: 9.6991e-05 - mean_absolute\n",
      "Epoch 00216: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 19s 2ms/sample - loss: 9.5732e-05 - mean_absolute_error: 0.0083 - val_loss: 2.1747e-05 - val_mean_absolute_error: 0.0035\n",
      "Epoch 217/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.6702e-05 - mean_absolute_error: 0.0083- ETA: 4s - loss: 9.5690e-05 -\n",
      "Epoch 00217: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 9.6963e-05 - mean_absolute_error: 0.0083 - val_loss: 3.3474e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 218/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1065e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00218: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 1.1256e-04 - mean_absolute_error: 0.0088 - val_loss: 3.6287e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 219/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0144e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00219: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 1.0314e-04 - mean_absolute_error: 0.0085 - val_loss: 5.4158e-05 - val_mean_absolute_error: 0.0060\n",
      "Epoch 220/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1343e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00220: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 18s 2ms/sample - loss: 1.1352e-04 - mean_absolute_error: 0.0088 - val_loss: 2.0392e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 221/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1332e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00221: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 19s 2ms/sample - loss: 1.1275e-04 - mean_absolute_error: 0.0086 - val_loss: 2.2081e-05 - val_mean_absolute_error: 0.0028\n",
      "Epoch 222/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0296e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00222: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 1.0339e-04 - mean_absolute_error: 0.0085 - val_loss: 1.7174e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 223/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0743e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00223: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 19s 2ms/sample - loss: 1.0692e-04 - mean_absolute_error: 0.0085 - val_loss: 8.3664e-05 - val_mean_absolute_error: 0.0063\n",
      "Epoch 224/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1292e-04 - mean_absolute_error: 0.0087  ETA: 11s - l - ETA: 7s - loss: 1.1680e-04 - mean_abso - ETA: 4s - loss: 1.1705e-04 \n",
      "Epoch 00224: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 21s 3ms/sample - loss: 1.1243e-04 - mean_absolute_error: 0.0087 - val_loss: 2.9283e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 225/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1308e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00225: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 19s 2ms/sample - loss: 1.1301e-04 - mean_absolute_error: 0.0087 - val_loss: 3.2803e-05 - val_mean_absolute_error: 0.0050\n",
      "Epoch 226/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0018e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00226: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 1.0006e-04 - mean_absolute_error: 0.0083 - val_loss: 2.1651e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 227/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.2051e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 00227: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 19s 2ms/sample - loss: 1.2049e-04 - mean_absolute_error: 0.0091 - val_loss: 3.7779e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 228/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.9239e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 00228: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 9.9227e-05 - mean_absolute_error: 0.0083 - val_loss: 2.5581e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 229/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.5114e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 00229: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 21s 3ms/sample - loss: 9.5478e-05 - mean_absolute_error: 0.0083 - val_loss: 1.8425e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 230/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.8633e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 00230: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 2ms/sample - loss: 9.8505e-05 - mean_absolute_error: 0.0082 - val_loss: 4.8858e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 231/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0106e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00231: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 1.0129e-04 - mean_absolute_error: 0.0083 - val_loss: 2.2141e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 232/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.9641e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 00232: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 19s 2ms/sample - loss: 1.0005e-04 - mean_absolute_error: 0.0083 - val_loss: 4.1775e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 233/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1110e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00233: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 2ms/sample - loss: 1.1078e-04 - mean_absolute_error: 0.0086 - val_loss: 2.9679e-05 - val_mean_absolute_error: 0.0058\n",
      "Epoch 234/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.6021e-05 - mean_absolute_error: 0.0083- ETA: 2s - loss: 9.4605e-05 - mean_absolute_error: 0.008 - ETA: 2s - loss: 9.4564e-05 - mean_absolute_e\n",
      "Epoch 00234: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 9.6230e-05 - mean_absolute_error: 0.0083 - val_loss: 3.1157e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 235/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.8587e-05 - mean_absolute_error: 0.0082- ETA: 1s - loss: 9.9804e-05 - mean_absolute_err\n",
      "Epoch 00235: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 9.8493e-05 - mean_absolute_error: 0.0082 - val_loss: 2.8700e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 236/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 8.9959e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00236: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 19s 2ms/sample - loss: 9.0094e-05 - mean_absolute_error: 0.0080 - val_loss: 4.6793e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 237/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.6242e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 00237: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 19s 2ms/sample - loss: 9.6395e-05 - mean_absolute_error: 0.0083 - val_loss: 2.5108e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 238/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.8504e-05 - mean_absolute_error: 0.0083- ETA: 5s - loss: 9.547\n",
      "Epoch 00238: val_loss improved from 0.00002 to 0.00002, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 9.9501e-05 - mean_absolute_error: 0.0083 - val_loss: 1.6221e-05 - val_mean_absolute_error: 0.0028\n",
      "Epoch 239/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0827e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00239: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 21s 3ms/sample - loss: 1.0848e-04 - mean_absolute_error: 0.0085 - val_loss: 1.8828e-05 - val_mean_absolute_error: 0.0029\n",
      "Epoch 240/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0683e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00240: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 19s 2ms/sample - loss: 1.0673e-04 - mean_absolute_error: 0.0086 - val_loss: 3.7978e-05 - val_mean_absolute_error: 0.0035\n",
      "Epoch 241/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.7039e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00241: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 9.6596e-05 - mean_absolute_error: 0.0080 - val_loss: 1.8104e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 242/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 8.5566e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00242: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 2ms/sample - loss: 8.5166e-05 - mean_absolute_error: 0.0078 - val_loss: 4.5784e-05 - val_mean_absolute_error: 0.0052\n",
      "Epoch 243/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.4305e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 00243: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 9.4496e-05 - mean_absolute_error: 0.0081 - val_loss: 4.1891e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 244/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0016e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00244: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 1.0071e-04 - mean_absolute_error: 0.0083 - val_loss: 2.3239e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 245/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 8.7674e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 00245: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 2ms/sample - loss: 8.7603e-05 - mean_absolute_error: 0.0079 - val_loss: 5.3427e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 246/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0212e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 00246: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 2ms/sample - loss: 1.0177e-04 - mean_absolute_error: 0.0081 - val_loss: 3.2353e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 247/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0430e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00247: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 1.0378e-04 - mean_absolute_error: 0.0082 - val_loss: 6.4702e-05 - val_mean_absolute_error: 0.0060\n",
      "Epoch 248/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1905e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 00248: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 1.1933e-04 - mean_absolute_error: 0.0089 - val_loss: 7.2023e-05 - val_mean_absolute_error: 0.0070\n",
      "Epoch 249/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1000e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00249: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 1.0981e-04 - mean_absolute_error: 0.0084 - val_loss: 1.7807e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 250/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0445e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00250: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 1.0426e-04 - mean_absolute_error: 0.0084 - val_loss: 3.2774e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 251/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0599e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00251: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 21s 3ms/sample - loss: 1.0560e-04 - mean_absolute_error: 0.0085 - val_loss: 1.8327e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 252/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.7740e-05 - mean_absolute_error: 0.0082- ETA: 6s - los\n",
      "Epoch 00252: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 9.8397e-05 - mean_absolute_error: 0.0082 - val_loss: 5.4626e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 253/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1101e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00253: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 1.1062e-04 - mean_absolute_error: 0.0086 - val_loss: 2.1867e-05 - val_mean_absolute_error: 0.0028\n",
      "Epoch 254/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 8.8561e-05 - mean_absolute_error: 0.0078- ETA: 8s - loss: 8.4299e-05 - mean_absolute_ - ETA: 6s - loss: 8.5167e\n",
      "Epoch 00254: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 25s 3ms/sample - loss: 8.8748e-05 - mean_absolute_error: 0.0078 - val_loss: 2.4689e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 255/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 8.2986e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 00255: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 20s 3ms/sample - loss: 8.2970e-05 - mean_absolute_error: 0.0078 - val_loss: 2.0661e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 256/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0197e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00256: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 21s 3ms/sample - loss: 1.0210e-04 - mean_absolute_error: 0.0083 - val_loss: 4.3221e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 257/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0018e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 00257: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 21s 3ms/sample - loss: 9.9902e-05 - mean_absolute_error: 0.0081 - val_loss: 5.9489e-05 - val_mean_absolute_error: 0.0058\n",
      "Epoch 258/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1216e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00258: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 21s 3ms/sample - loss: 1.1156e-04 - mean_absolute_error: 0.0088 - val_loss: 2.3891e-05 - val_mean_absolute_error: 0.0035\n",
      "Epoch 259/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0330e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00259: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 21s 3ms/sample - loss: 1.0300e-04 - mean_absolute_error: 0.0083 - val_loss: 2.7686e-05 - val_mean_absolute_error: 0.0048\n",
      "Epoch 260/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0057e-04 - mean_absolute_error: 0.0082- ETA: 4s - loss: 9.5500e-05 -\n",
      "Epoch 00260: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 21s 3ms/sample - loss: 1.0121e-04 - mean_absolute_error: 0.0083 - val_loss: 4.6763e-05 - val_mean_absolute_error: 0.0062\n",
      "Epoch 261/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.5077e-05 - mean_absolute_error: 0.0082- ET\n",
      "Epoch 00261: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 21s 3ms/sample - loss: 9.4717e-05 - mean_absolute_error: 0.0082 - val_loss: 1.6410e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 262/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.7861e-05 - mean_absolute_error: 0.0081  ETA: 12s - loss: 9.6761e-05 - mean_absolute_error:  - ETA: 12s - loss: 9.3771e-05 - mean_absolute_error: 0.  - ETA: 5s - loss: 1.0032e-04 - mean_absolute_error: 0.008 - ETA: 5s - loss: 1.0003e-04\n",
      "Epoch 00262: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 22s 3ms/sample - loss: 9.7545e-05 - mean_absolute_error: 0.0081 - val_loss: 2.3138e-05 - val_mean_absolute_error: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0544e-04 - mean_absolute_error: 0.0086  ETA: 14s - loss:\n",
      "Epoch 00263: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 23s 3ms/sample - loss: 1.0491e-04 - mean_absolute_error: 0.0086 - val_loss: 2.0538e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 264/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1324e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00264: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 21s 3ms/sample - loss: 1.1350e-04 - mean_absolute_error: 0.0087 - val_loss: 8.2789e-05 - val_mean_absolute_error: 0.0063\n",
      "Epoch 265/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0577e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00265: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 22s 3ms/sample - loss: 1.0585e-04 - mean_absolute_error: 0.0086 - val_loss: 1.0475e-04 - val_mean_absolute_error: 0.0083\n",
      "Epoch 266/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1011e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00266: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 23s 3ms/sample - loss: 1.0961e-04 - mean_absolute_error: 0.0087 - val_loss: 3.1122e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 267/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0732e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00267: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 21s 3ms/sample - loss: 1.0676e-04 - mean_absolute_error: 0.0085 - val_loss: 1.6930e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 268/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 8.9689e-05 - mean_absolute_error: 0.0081  ETA: 19s - loss: 9.0554e-05 - mean_absolute_error:  - ETA: 18s\n",
      "Epoch 00268: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 8.9560e-05 - mean_absolute_error: 0.0081 - val_loss: 1.9913e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 269/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 8.8507e-05 - mean_absolute_error: 0.0077  ETA: 19s -  - ETA: 9s - loss: 8.1089e-05  - ETA: 4s - loss: 8.5009e-05 - mean\n",
      "Epoch 00269: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 23s 3ms/sample - loss: 8.8578e-05 - mean_absolute_error: 0.0078 - val_loss: 2.2335e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 270/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0000e-04 - mean_absolute_error: 0.0083- ETA: 0s - loss: 1.0117e-04 - mean_absolute_error: 0.0\n",
      "Epoch 00270: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 23s 3ms/sample - loss: 9.9869e-05 - mean_absolute_error: 0.0083 - val_loss: 2.1822e-05 - val_mean_absolute_error: 0.0048\n",
      "Epoch 271/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.6192e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 00271: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 9.5948e-05 - mean_absolute_error: 0.0081 - val_loss: 2.1026e-05 - val_mean_absolute_error: 0.0029\n",
      "Epoch 272/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.9057e-05 - mean_absolute_error: 0.0081- ETA: 5s - loss: 1.0298e-04 - mean_abs - ETA: 2s - loss: 1.0156e-04 - mean_absolute_error: 0. - ETA: 1s - loss: 1.0095e-04 - mean_absolute_error\n",
      "Epoch 00272: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 23s 3ms/sample - loss: 9.8867e-05 - mean_absolute_error: 0.0081 - val_loss: 1.8329e-05 - val_mean_absolute_error: 0.0035\n",
      "Epoch 273/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.7853e-05 - mean_absolute_error: 0.0082\n",
      "Epoch 00273: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 23s 3ms/sample - loss: 9.7974e-05 - mean_absolute_error: 0.0082 - val_loss: 5.8347e-05 - val_mean_absolute_error: 0.0077\n",
      "Epoch 274/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.7598e-05 - mean_absolute_error: 0.0082- ETA: 1s - loss: 9.5158e-05 - mean_absolute_error\n",
      "Epoch 00274: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 23s 3ms/sample - loss: 9.7785e-05 - mean_absolute_error: 0.0082 - val_loss: 1.9285e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 275/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.1645e-05 - mean_absolute_error: 0.0079  ETA: 12s - loss: 8.7157e-05 - - ETA: 10s - lo - ETA: 2s - loss: 9.2168e-05 - mean_absolute_err\n",
      "Epoch 00275: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 9.1488e-05 - mean_absolute_error: 0.0079 - val_loss: 2.0724e-05 - val_mean_absolute_error: 0.0035\n",
      "Epoch 276/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.4282e-05 - mean_absolute_error: 0.0081  ETA: 18s - loss: 1.0368e-04 - mean_absolute_error: 0.00 - ETA: 17s - loss: 1.0189e-04 - mean_absolute_error: 0.00 - ETA: 17s - loss: 1.0017e-04 - mean_absolute_error - ETA: 16s - loss: 9.8281e-05 - mean_absolute_error: 0.00 - ETA: 16s - loss: 9.6673e-05 - mean_absolute_error: 0.00 - ETA: 16s - loss: 9.5934e-05 - mean_absolute_e - ETA: 15s - loss: 8.9681e-05 - mean_absolu - ETA: 14s - l - ETA: 1s - loss: 9.4681e-05 - mean_absolute_error: 0\n",
      "Epoch 00276: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 22s 3ms/sample - loss: 9.4200e-05 - mean_absolute_error: 0.0081 - val_loss: 2.3075e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 277/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 8.9580e-05 - mean_absolute_error: 0.0078- ETA: 6s - loss: 8.5575e-05 - mean_abs - ETA: 3s - loss: 8.7915e-05 - mean_absol - ETA: 0s - loss: 8.9820e-05 - mean_absolute_error: 0.007\n",
      "Epoch 00277: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 22s 3ms/sample - loss: 8.9370e-05 - mean_absolute_error: 0.0078 - val_loss: 2.3623e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 278/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.1809e-05 - mean_absolute_error: 0.008 - ETA: 0s - loss: 9.1467e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00278: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 23s 3ms/sample - loss: 9.1141e-05 - mean_absolute_error: 0.0080 - val_loss: 3.1548e-05 - val_mean_absolute_error: 0.0062\n",
      "Epoch 279/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.4389e-05 - mean_absolute_error: 0.0079  ETA: 20s - loss: 9.6586e-05 - mean_absolute_error: 0.00 - ETA: 20s - loss: 9.1275e- - ETA: 18s - loss: 9.3507e-05 - mean_absolute_err  - ETA: 3s - loss: 9.3267e-05 - mean_ab\n",
      "Epoch 00279: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 9.4816e-05 - mean_absolute_error: 0.0080 - val_loss: 5.5569e-05 - val_mean_absolute_error: 0.0050\n",
      "Epoch 280/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.2945e-05 - mean_absolute_error: 0.0078  ETA: 13s - - ETA: 9s - loss: 8.8885e-05 - mean_absolute_error:  - ETA: 8s - l\n",
      "Epoch 00280: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 25s 3ms/sample - loss: 9.2527e-05 - mean_absolute_error: 0.0078 - val_loss: 1.7084e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 281/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.2461e-05 - mean_absolute_error: 0.0081- ETA: 8s - loss: 9.6532e-05  - ETA: 0s - loss: 9.1981e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 00281: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 32s 4ms/sample - loss: 9.2053e-05 - mean_absolute_error: 0.0081 - val_loss: 4.0802e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 282/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.9058e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00282: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 27s 3ms/sample - loss: 9.9688e-05 - mean_absolute_error: 0.0080 - val_loss: 3.6075e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 283/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1883e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00283: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 22s 3ms/sample - loss: 1.1852e-04 - mean_absolute_error: 0.0088 - val_loss: 2.7875e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 284/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1427e-04 - mean_absolute_error: 0.0087  ETA: 18s - loss: 1.5325e-04 - mean_absolute_error: 0.00 - ETA: 17s - loss: 1.4699e-04 - mean_absolu - ETA: 16s - loss: 1.2504e-04 - mea\n",
      "Epoch 00284: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 22s 3ms/sample - loss: 1.1401e-04 - mean_absolute_error: 0.0087 - val_loss: 7.1399e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 285/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.8463e-05 - mean_absolute_error: 0.0082  ETA: 13s - loss: 1.0720e - ETA: 0s - loss: 9.8874e-05 - mean_absolute_error: 0.008 - ETA: 0s - loss: 9.9120e-05 - mean_absolute_error: 0.00\n",
      "Epoch 00285: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 9.8358e-05 - mean_absolute_error: 0.0082 - val_loss: 3.9780e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 286/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.7506e-05 - mean_absolute_error: 0.0082- ETA: 7s - loss: 1\n",
      "Epoch 00286: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 9.7246e-05 - mean_absolute_error: 0.0082 - val_loss: 1.9563e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 287/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.4932e-05 - mean_absolute_error: 0.0082- ETA: 1s - loss: 9.4674e-05 - mean_absolute_error: 0.008 - ETA: 1s - loss: 9.4602e-05 - mean_absolute_error: \n",
      "Epoch 00287: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 28s 4ms/sample - loss: 9.5514e-05 - mean_absolute_error: 0.0082 - val_loss: 2.0098e-05 - val_mean_absolute_error: 0.0044\n",
      "Epoch 288/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0230e-04 - mean_absolute_error: 0.0082- ETA: 6s - loss: 9.3466e-05 - mean_abs - ETA: 2s - loss: 1.0035e-04 - mean_absolute_error: - ETA: 0s - loss: 1.0079e-04 - mean_absolute_error: 0.\n",
      "Epoch 00288: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 25s 3ms/sample - loss: 1.0199e-04 - mean_absolute_error: 0.0082 - val_loss: 2.0146e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 289/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.1334e-04 - mean_absolute_error: 0.0087  ETA: 20s - loss: 1.2342e-04 - mean_absolute_error:  - ETA: 19s - loss: 1.1881e-04 - mean_absolute_e - ETA: 18s - loss: 1.1721e-04 - mean_absolute_error:  - ETA: 18s - loss: 1.0853e-04 - mean_absolute_error: 0. - E - ETA: 4s - loss: 1.1576e-04 - mean_absolute_error: 0 - ETA: 4s - loss: 1.1713e-04 - mean_a\n",
      "Epoch 00289: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 23s 3ms/sample - loss: 1.1294e-04 - mean_absolute_error: 0.0087 - val_loss: 2.5103e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 290/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0342e-04 - mean_absolute_error: 0.0085  ETA: 20s - loss: 6.7121e-05 - mean_absolute_error - ETA - ETA: 11s - los - ETA: 4s - loss: 9.9623e-05 - mean_abso - ETA: 0s - loss: 1.0210e-04 - mean_absolute_error: 0.0\n",
      "Epoch 00290: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 1.0307e-04 - mean_absolute_error: 0.0085 - val_loss: 3.1777e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 291/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0623e-04 - mean_absolute_error: 0.0087  ETA: 19s - loss: 1.2081e- - ETA: 16s - loss: 1.1704e-04 - mean_absolute_error:  - ETA: 15s - loss: 1.2292e-04 - mean_absolute_error: 0.00 - ETA - ETA: 10s - loss: 1.1104e-04 - ETA: 6s - loss: 1.0194e-04 - mean_absolute_error:  - ETA: 5s - loss: 1.0216e-04 \n",
      "Epoch 00291: val_loss improved from 0.00002 to 0.00002, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 23s 3ms/sample - loss: 1.0559e-04 - mean_absolute_error: 0.0087 - val_loss: 1.5537e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 292/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 8.3480e-05 - mean_absolute_error: 0.0077- ETA: 3s - loss: 8.1821e-05 - mean_absolute_error: 0.007 - ETA: 3s - loss: 8.2548e-05 - mean_absolute_error: 0.00 - ETA: 3s - loss: 8.2066e-05 - mean_absolu\n",
      "Epoch 00292: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 8.3892e-05 - mean_absolute_error: 0.0078 - val_loss: 4.4771e-05 - val_mean_absolute_error: 0.0050\n",
      "Epoch 293/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.9639e-05 - mean_absolute_error: 0.0082  ETA: 18s - loss: 1.0148e-04 - mean_absolute_error - ETA: 17s - loss: 9.5248e-05 - m - ETA: 15s - loss: 1.0526e-04 - mean_absolute - ETA: 13s - loss: 9.9601e- - ETA: 10s - loss: 9.432 - ETA: 4s - loss: 9.2048e-05 - mean_absolute_error: 0. - ETA: 3s - loss: 9.3888e-05 - mean_abs\n",
      "Epoch 00293: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 9.9079e-05 - mean_absolute_error: 0.0082 - val_loss: 8.7975e-05 - val_mean_absolute_error: 0.0060\n",
      "Epoch 294/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.8276e-05 - mean_absolute_error: 0.0082  ETA: 15s - loss: 1. - ETA: 12s - loss: 1.0635e-04 - mean_absolute_error:  - ETA: 11s - loss: 1.0526e-04 - mean - ETA: 9s - loss: 1.1231e-04 - mean_absolute_error:  - ETA: 8s - loss: 1.1120e-04 - mea - ETA: 3s - loss: 1.0165e-04 - mean_abs\n",
      "Epoch 00294: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 9.9253e-05 - mean_absolute_error: 0.0082 - val_loss: 1.7748e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 295/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.1393e-05 - mean_absolute_error: 0.0078  ETA: 14s - loss: 8.9027 - ETA: 10s - loss: 8.8127e-05 - mean_absolute - ETA: 9s - los - ETA: 0s - loss: 9.2074e-05 - mean_absolute_error: 0.0\n",
      "Epoch 00295: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 25s 3ms/sample - loss: 9.1512e-05 - mean_absolute_error: 0.0078 - val_loss: 1.7269e-05 - val_mean_absolute_error: 0.0027\n",
      "Epoch 296/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0571e-04 - mean_absolute_error: 0.0083- ETA: 6s - loss: 1.0529e-04 - mea - ETA: 1s - loss: 1.0499e-04 - mean_absolute_erro\n",
      "Epoch 00296: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 25s 3ms/sample - loss: 1.0683e-04 - mean_absolute_error: 0.0083 - val_loss: 3.0462e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 297/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.5184e-05 - mean_absolute_error: 0.0081  ETA: 23s - loss: 8.5581e-05 - m - ETA: 20s - loss - ETA: 15s - loss: 1.0216e-04 - mean_absolute_error:  - ETA:  - ETA: 9s - loss: 1.0004e-04 - mean_absolute_error: 0.00 - ETA: 9s - loss: 9.9432e- - ETA: 3s - loss: 9.7890e-05 - mean_absol - ETA: 0s - loss: 9.5311e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 00297: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 23s 3ms/sample - loss: 9.5071e-05 - mean_absolute_error: 0.0081 - val_loss: 2.1008e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 298/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0615e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00298: val_loss improved from 0.00002 to 0.00002, saving model to results\\2020-05-13_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
      "7868/7868 [==============================] - 25s 3ms/sample - loss: 1.0578e-04 - mean_absolute_error: 0.0083 - val_loss: 1.5153e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 299/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.2764e-05 - mean_absolute_error: 0.0080  ETA: 12s - loss: 9.375 - ETA: 9s\n",
      "Epoch 00299: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 9.2568e-05 - mean_absolute_error: 0.0080 - val_loss: 2.0686e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 300/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.1671e-05 - mean_absolute_error: 0.0080  - ETA: 11s - loss: 9.8754e-05 - mean_absolute_error: 0.00 - ETA: 11s - loss: 9.8084e-05 - ETA: 6s - loss: 9.5396e-05 - mean_absolute_error: 0.008 - ETA: 6s - loss: 9.5257e-\n",
      "Epoch 00300: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 9.1397e-05 - mean_absolute_error: 0.0080 - val_loss: 2.6946e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 301/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.4784e-05 - mean_absolute_error: 0.0081\n",
      "Epoch 00301: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 25s 3ms/sample - loss: 9.4423e-05 - mean_absolute_error: 0.0081 - val_loss: 3.0284e-05 - val_mean_absolute_error: 0.0048\n",
      "Epoch 302/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.7482e-05 - mean_absolute_error: 0.0080  ETA: - ETA: 0s - loss: 9.7930e-05 - mean_absolute_error: 0.008\n",
      "Epoch 00302: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 27s 3ms/sample - loss: 9.7192e-05 - mean_absolute_error: 0.0080 - val_loss: 3.3782e-05 - val_mean_absolute_error: 0.0049\n",
      "Epoch 303/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0190e-04 - mean_absolute_error: 0.0081  ETA: 10s - loss: 9.9061e-05 - mean_absolut - ETA: 7s - loss: 9.8916e-05 - me - ETA: 2s - loss: 1.0114e-04 - mean_absolute_er\n",
      "Epoch 00303: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 25s 3ms/sample - loss: 1.0139e-04 - mean_absolute_error: 0.0081 - val_loss: 2.7980e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 304/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0200e-04 - mean_absolute_error: 0.0081  ETA: 11s - loss: 9.6005e-05 - mean_absolute_err - ETA: 10s - - ETA: 1s - loss: 1.0233e-04 - mean_absolute_error: 0.008 - ETA: 1s - loss: 1.0283e-04 - mean_absolute_error\n",
      "Epoch 00304: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 25s 3ms/sample - loss: 1.0231e-04 - mean_absolute_error: 0.0081 - val_loss: 3.2007e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 305/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.4459e-05 - mean_absolute_error: 0.0080- ETA: 7s - loss: 9.\n",
      "Epoch 00305: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 27s 3ms/sample - loss: 9.4312e-05 - mean_absolute_error: 0.0080 - val_loss: 1.7726e-05 - val_mean_absolute_error: 0.0025\n",
      "Epoch 306/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 1.0072e-04 - mean_absolute_error: 0.0080  ETA: 20s - loss: 6.4032e-05 - mean_absolute_error: 0. - ETA: 20s - loss: 6.5976e-05 - mean_absolute_error: 0.00 - ETA: 20s - loss: 6.3398 - ETA: 17s - loss: 7. - ETA: 13s - loss: 8.2300 - ETA: 10s - loss: 9.4421 - ETA: 5s - loss: 1.0029e-04 - mean_absolute_error - ETA: 4s - loss: 1.0236e-04 - mean_\n",
      "Epoch 00306: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 1.0049e-04 - mean_absolute_error: 0.0080 - val_loss: 2.2254e-05 - val_mean_absolute_error: 0.0041\n",
      "Epoch 307/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.0567e-05 - mean_absolute_error: 0.00792 ETA: 17s - loss: 9.3406e-05 - mean_ab - ETA: 15s - loss - ETA: 11s - loss: 9.9422e-05 - mean_absolute_e - ETA: 9s - loss: 1.0041e-04 - mean_absolute_error: 0.0082 - ETA: 9s - loss: 9.9965e-05 - mean_absolute_error: 0. - ETA: 8s - loss: 9.881 - ETA: 2s - loss: 9.3174e-05 - mean_absolute_error: 0. - ETA: 1s - loss: 9.1843e-05 - mean_absolute_error\n",
      "Epoch 00307: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 9.0856e-05 - mean_absolute_error: 0.0079 - val_loss: 1.9447e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 308/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 8.6281e-05 - mean_absolute_error: 0.0078  ETA: 13s - loss: 8.7781e-05 - mean - ETA: 1s - loss: 8.6070e-05 - mean_absolute_error\n",
      "Epoch 00308: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 8.6021e-05 - mean_absolute_error: 0.0078 - val_loss: 2.9249e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 309/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 8.9718e-05 - mean_absolute_error: 0.0079  ETA: 19s - loss: 9.6293e-05 - m - ETA: - ETA: 1s - loss: 8.9536e-05 - mean_absolute_error\n",
      "Epoch 00309: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 8.9964e-05 - mean_absolute_error: 0.0079 - val_loss: 2.9808e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 310/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 8.9722e-05 - mean_absolute_error: 0.0080  ETA: 10s - loss: 9.0345e-05 - mean_abso - ETA: 8s - los\n",
      "Epoch 00310: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 8.9829e-05 - mean_absolute_error: 0.0080 - val_loss: 3.6877e-05 - val_mean_absolute_error: 0.0035\n",
      "Epoch 311/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.7491e-05 - mean_absolute_error: 0.0080\n",
      "Epoch 00311: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 26s 3ms/sample - loss: 9.7654e-05 - mean_absolute_error: 0.0080 - val_loss: 2.1573e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 312/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.2122e-05 - mean_absolute_error: 0.0080  ETA: - ETA: 0s - loss: 9.1293e-05 - mean_absolute_error: 0.\n",
      "Epoch 00312: val_loss did not improve from 0.00002\n",
      "7868/7868 [==============================] - 24s 3ms/sample - loss: 9.1950e-05 - mean_absolute_error: 0.0080 - val_loss: 1.8613e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 313/400\n",
      "7808/7868 [============================>.] - ETA: 0s - loss: 9.3210e-05 - mean_absolute_error: 0.0081  ETA: 15s - loss: 8.6030"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\n",
    "\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)\n",
    "\n",
    "model.save(os.path.join(\"results\", model_name) + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n",
    "                feature_columns=FEATURE_COLUMNS, shuffle=False)\n",
    "\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 11.787807\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "mse, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform(mae.reshape(1, -1))[0][0]\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data, classification=False):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][:N_STEPS]\n",
    "    # retrieve the column scalers\n",
    "    column_scaler = data[\"column_scaler\"]\n",
    "    # reshape the last sequence\n",
    "    last_sequence = last_sequence.reshape((last_sequence.shape[1], last_sequence.shape[0]))\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    predicted_price = column_scaler[\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 30 days is 288.04$\n"
     ]
    }
   ],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(model, data):\n",
    "    y_test = data[\"y_test\"]\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    # last 200 days, feel free to edit that\n",
    "    plt.plot(y_test[-200:], c='b')\n",
    "    plt.plot(y_pred[-200:], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2dd3xU5fKHn4GE3ov+aAoqqEgJRUWKXqWqCBawKyoWrl4VO1ivXisq6r3XcrEXUBRFsYIoSgfphN4hgNJLqEl4f3/Mnuwm2TSSs7tJ5vl8lrN72s5ulvM9M/O+M+KcwzAMwzAASkXbAMMwDCN2MFEwDMMw0jFRMAzDMNIxUTAMwzDSMVEwDMMw0omLtgEFoVatWq5hw4bRNsMwDKNIMXv27G3OudrhthVpUWjYsCGzZs2KthmGYRhFChFZl902Cx8ZhmEY6ZgoGIZhGOmYKBiGYRjpFOmcQjhSUlJISkri4MGD0TbFyAflypWjfv36xMfHR9sUwyjRFDtRSEpKonLlyjRs2BARibY5Rh5wzrF9+3aSkpJo1KhRtM0xjBJNsQsfHTx4kJo1a5ogFCFEhJo1a5p3ZxgxQLETBcAEoQhifzPDiA2KpSgYhhFZZsyAyZOjbYVRGJgo+MTo0aMREZYuXZrrvh988AGbNm066vf67bff6NmzZ9j1VatWpVWrVpx66qk8+eSTYY/ftGkTffr0Oer3N4yBA+GSS+DAgWhbYhQUEwWf+PTTT+nYsSOfffZZrvsWVBRyolOnTsydO5dZs2bxySefMHv27AzbU1NTqVu3LqNGjfLl/Y2SwYoVsG0bfPRRtC0xCoqJgg8kJyczZcoU3n333SyiMGTIEJo3b07Lli0ZNGgQo0aNYtasWVxzzTUkJCRw4MABGjZsyLZt2wCYNWsWf/vb3wCYOXMm7du3p1WrVrRv355ly5bl2aaKFSvSpk0bVq1axQcffEDfvn256KKL6NatG2vXrqVZs2YApKWlcf/999O8eXNatGjBf/7zHwBmz57NOeecQ5s2bejevTubN28uhG/KKA7s2gXbt+vzoUNh3jzYujW6NhlHT7EbkhrKwIH6Ay1MEhLg1Vdz3ufrr7+mR48eNGnShBo1ajBnzhxat27Njz/+yNdff82MGTOoUKECO3bsoEaNGvz3v//lpZdeom3btjme95RTTmHixInExcUxfvx4Hn74Yb788ss82b19+3amT5/OY489xh9//MG0adNYsGABNWrUYO3aten7DRs2jDVr1jB37lzi4uLYsWMHKSkp3HnnnXzzzTfUrl2bkSNH8sgjj/Dee+/l6b2N4sNvv8Gxx8KppwbXrVqly7594YsvoFUraNMGrCxZ0aRYi0K0+PTTTxk4cCAAV155JZ9++imtW7dm/Pjx3HjjjVSoUAGAGjVq5Ou8u3fvpl+/fqxYsQIRISUlJddjJk2aRKtWrShVqhSDBg3itNNO448//qBr165h33/8+PEMGDCAuLi4dBsTExNJTEyka9eugHoTderUyZftRuyzeTNUrw7lyoXfnpoKF18M7drBTz8F13ui8PDDcPnl8Pnn8NVXcOiQ5hh274bjj/fffqNwKNaikNsdvR9s376dX3/9lcTERESEtLQ0RIQhQ4bgnMvT0Mu4uDiOHDkCkGHs/mOPPca5557L6NGjWbt2bXpYKSc6derEd999l2V9xYoVw+4fzkbnHKeddhrTpk3L9f2Mosm+fdCkCZQvD089BQMGZN1nxgy9wE+ZogIRuG9IF4WTTlJPOjVVPYalS+GVV2DsWNiwIbi/Edv4llMQkXIiMlNE5ovIIhF5MrB+uIgsE5FEEXlPROID60VE/i0iK0VkgYi09ss2Pxk1ahTXX38969atY+3atWzYsIFGjRoxefJkunXrxnvvvcf+/fsB2LFjBwCVK1dm79696edo2LBhekI4NDy0e/du6tWrB2hy2g+6devGW2+9RWpqarqNJ598Mlu3bk0XhZSUFBYtWuTL+xvRYelSSE4GEbj9djh8OOs+nneQnAzz5wfXr1wJ//d/UKmSvm7eXJcLF2q46c8/VUiMooGfieZDwHnOuZZAAtBDRNoBw4FTgOZAeeDmwP7nA40Dj1uBN320zTc+/fRTLrnkkgzrLrvsMkaMGEGPHj3o1asXbdu2JSEhgZdeegmAG264gQEDBqQnmp944gnuvvtuOnXqROnSpdPP8+CDDzJ48GA6dOhAWlqaL/bffPPNHHfccbRo0YKWLVsyYsQIypQpw6hRo3jooYdo2bIlCQkJTJ061Zf3N6KDN3L68svBOQjcr2Rg7Fg48UR9PmmSjjbavVs9BW89qMcRH6/7rwtU7R892l/7jULEOef7A6gAzAHOzLT+HuCZwPP/AVeFbFsG1MnpvG3atHGZWbx4cZZ1RtHA/nbR45FHnCtd2rmPPnIOnEtMzLh961bnRJx76innGjZ07txznatTx7lWrZyrW9e566/PuH+LFs6VLavnOu44fRw5ErnPY+QMMMtlc131dUiqiJQWkXnAFuBn59yMkG3xwHWAl7KqB2wIOTwpsC7zOW8VkVkiMmurjXszjEJh6VI44QTwxg94Q0w9fvxRPYju3aFTJ5gwQRPTc+fCpk2aTwilRQtNNJcvrwno9et1XyP28VUUnHNpzrkEoD5whog0C9n8BjDROTcp8DpcBtaFOecw51xb51zb2rXDthg1DCOfLFmiw0xr1tTXmcNH77yjIaK2beHss3XdM89A60DmLzR8BMG8wumn64gl0PyCEftEZDyAc26XiPwG9AASReQJoDZwW8huSUCDkNf1AX+m+RqGkU5qqs5I7tkzKAqhnsLixTBxIgwZAqVKwbXXQuXK0KcPtG8PvXqpWITiiUL79jqvoXp1fQ8j9vFz9FFtEakWeF4e6AIsFZGbge5o/uBIyCFjgOsDo5DaAbudczZt1jAKgEb1g6+3btVJZuPHB9etXg0pKRk9hVBR+N//oEwZuOEGfV2uHFxxBZQuDX/7m85obtIk4/u2a6fCcOml+rpxY1i+vLA/neEHfoaP6gATRGQB8AeaU/gOeAs4FpgmIvNE5PHA/j8Aq4GVwNvA7T7aZhglgquuggsu0OfOwa23wqhRcP75MHy4rvdGHp1yClSooAIQKgqffw69e0N20dpSYa4i1avDggUaPgIVDfMUiga+hY+ccwuAVmHWh33PQEb8Dr/sMYySxt69OhT08GEN/6xcCV9/DY8/rsNFH3gArrlG8wmgoiCi3oInCocO6TyDFi0KZkvjxvDJJzrDuXz5gp3L8BcriOcDpUuXJiEhgWbNmtG3b9/0yWpHQ2hZ7DFjxvD8889nu++uXbt444038v0e//znP9PnTGReX69evfTPMmbMmLDH52aX4T+//x68uHv8/LMKQny8zlAeMEDDPY8/rt7D5s160V+5Ur2AatX0uJo1g4lmr+5h3boFs69xY116s5+N2MVEwQfKly/PvHnzSExMpEyZMrz11lsZtjvn0stY5IdevXoxaNCgbLcfrSjkxD333MO8efP44osvuOmmm7LYnZqamqtdhv9cdRXcfXfGdd9+qxf6J59UwWjaVD2H0qWhQWBIx8aNOsGsYcPgcaGewsaNuiwsUbAQUuxjouAznTp1YuXKlaxdu5ZTTz2V22+/ndatW7NhwwbGjRvHWWedRevWrenbty/JyckA/PTTT5xyyil07NiRr776Kv1cH3zwAf/4xz8A+Ouvv7jkkkto2bIlLVu2ZOrUqQwaNIhVq1aRkJDAAw88AMCLL77I6aefTosWLXjiiSfSz/XMM89w8skn06VLlzyV4D711FOJi4tj27Zt3HDDDdx7772ce+65PPTQQ7naBfDJJ59wxhlnkJCQwG233ebbjOySyK5dekc/daomjAHS0uD77zV3MHAgvPwyjBsX9Abq19flhg0qCqEF62rUCIqC1+ajXpYZQ/nDRKHoULxLVEWrdnaA1NRUfvzxR3r06AHAsmXLeP/993njjTfYtm0bTz/9NOPHj6dixYq88MILDB06lAcffJBbbrmFX3/9lZNOOokrrrgi7LnvuusuzjnnHEaPHk1aWhrJyck8//zzJCYmMi/wmceNG8eKFSuYOXMmzjl69erFxIkTqVixIp999hlz584lNTWV1q1b06ZNmxw/y4wZMyhVqhTe3JDly5czfvx4SpcunaEOUzi7lixZwsiRI5kyZQrx8fHcfvvtDB8+nOuvvz5P36ORM17YaN8+mD1bR/788YeONLroIo3h33tvxmM8T2H9en1cdFFwW6in4IlCQT2FqlU1RGWiEPsUb1GIEgcOHCAhIQFQT6F///5s2rSJ448/nnbt2gEwffp0Fi9eTIcOHQA4fPgwZ511FkuXLqVRo0Y0DtxaXXvttQwbNizLe/z66698FGhzVbp0aapWrcrOnTsz7DNu3DjGjRtHq1aa709OTmbFihXs3buXSy65JL2Ed69evbL9LK+88gqffPIJlStXZuTIkekVVPv27ZuhLlNOdn388cfMnj2b0wNDUQ4cOMAxxxyTl6/SyAOhHV9//11FYexYTRp37x7+GE8U5s6FgwfhuOOC27ycgnMaPipbVr2HgtK4sYlCUaB4i0I0amcTzClkJrRctXOOrl278umnn2bYZ968eXkqr50XnHMMHjyY2267LcP6V199Nc/vcc8993D//fdnWZ9d6e3s7OjXrx/PPfdcno8x8s6SJTqM9PjjdZTRQw9pkrlt2+wv5hUr6rBRr3ppaPioZk1NUO/bp55C3boqMAWlcWO1y4htLKcQJdq1a8eUKVNYuXIlAPv372f58uWccsoprFmzhlWBYRqZRcOjc+fOvPmmFpJNS0tjz549WUpwd+/enffeey89V7Fx40a2bNnC2WefzejRozlw4AB79+7l22+/LbTPFc6uzp07M2rUKLZs2QJoOe51XvlMo8AsWaLzAM47DyZPhp07Yfp06NIl5+Pq14c5c/R55pwCaAhp48aCh4486tWDv/7KOJnOiD1MFKJE7dq1+eCDD7jqqqto0aIF7dq1Y+nSpZQrV45hw4Zx4YUX0rFjR47PpmXVa6+9xoQJE2jevDlt2rRh0aJF1KxZkw4dOtCsWTMeeOABunXrxtVXX81ZZ51F8+bN6dOnD3v37qV169ZcccUVJCQkcNlll9GpU6dC+1zh7GratClPP/003bp1o0WLFnTt2tV6PBciS5fqbOTOnWHPHrj5Zk00BxrlZUuDBlriArJ6CqCisGlTwZPMHjVqqF0h9y1GLJJd+dSi8LDS2cUL+9vlnwMHnCtVyrnHH3cuNdW5rl21sEWFCs4dPJjzsbfdpvtWrpyxrPXEibp+3DjnKlVybuDAwrH1/ff1vKtXF875SjLNmjk3ZMjRH0+0SmcbhuEvK1bAkSM6G7l0aRgxQuccdOumCeKc8JLNxx2XMWfghY/WrtUua4UVPvLOG66Bj5F3du6ExMTCyfOEo3gnmg2jGHPkCHgpp1NP1WWtWtoqMy/9kL25CpkjlF74aOFCXRZm+AhMFAqKN4LLm/tR2BRLUXBhms8bsY2z7GO+ufJK+OILLV3tlaoGqFIlb8d7nkJmUfAu3jMCLbHMU4gt/BaFYhc+KleuHNu3b7eLTBHCOcf27dspV65ctE0pMhw4AF9+qfWMvv5aQ0f5JTtRKFNGayTNnKmvTRRiixUrNHR0wgn+nL/YeQr169cnKSkJa9VZtChXrhz1vXiGkSvLl2v46Nxzjz62fOKJWhzvyiuzbvv+e7jtNu2W1qBB1u1HQ/XqujRRKBjLl6uQ+3UPVexEIT4+nkaNGkXbDMPwlcWLddm06dGfo1QpLZYXjgoV4OOPdU5BYUViy5bVSXMmCgVjxQr/QkdQDMNHhlESWLJEQ0Z+Xhyg8Ee41KhholAQnDNRMAwjDIsXa/gnt2GnsYaJQsHYtg127zZRMAwjE4sXFyx0FC1MFAqG3yOPwETBMIochw/rxcFEoeSxfLkuTRQMw0hn5UqtWWSiUPKYM0dDhn6OpTFRMIwiRmGMPIoWnijkZRrRqlVarmP3bv/tKgqkpcGoUdpNLz7ev/fxTRREpJyIzBSR+SKySESeDKxvJCIzRGSFiIwUkTKB9WUDr1cGtjf0yzbDKMrMn68jj04+OdqW5J8aNYK9GnJj0iTtv1DYzROLKlOmaNvVbJoxFhp+egqHgPOccy2BBKCHiLQDXgBecc41BnYC/QP79wd2OudOAl4J7GcYRiamT4cWLXQuQVEjP7Oat23T5caN/tmTIzt3wptvaq/S5s2hdWu47DIYMgSSkiJuzsiR2lq1Z09/38c3UQhUaE0OvIwPPBxwHjAqsP5D4OLA896B1wS2dxYrYGQYGUhL05pEga6uRY4iIQrz58Ott2olwNtvh0WL4KSToE4drRL40ENaWvaKK4KxPJ9JTdXQUc+eUKmSv+/la05BREqLyDxgC/AzsArY5ZwLtPYgCfBqMNYDNgAEtu8GaoY5560iMktEZlkpC6M4s3Nn1mvO0qXapKYkiULEbso3boSrr4aEBPjkE7jmGs3srloFo0dr7Y/lyzXT/+CD8MMPuu9//+t7O7nff4ctW/wPHYHPZS6cc2lAgohUA0YDp4bbLbAM5xVk+aadc8OAYQBt27a1qndGseXJJ+HttzWOvHu3XhgOHtRtxVUUnNOcQ9myEfQUDh+GV16Bf/1Lb8kfewwGDsy+wfWJJ8Lzz8P998ONN8Kdd6pInHBC8FGzphqelga1a6vYNGt21CaOHKkewgUXHPUp8kxEah8553aJyG9AO6CaiMQFvIH6wKbAbklAAyBJROKAqoANXjNKLAsWwP798NVXGjr4/nuNWlSv7n95C7/wejVkJwo//QR9+8K6dREShbFj4a671APo3RuGDs17+dFateCbb7SpxZw5sHq1Pn79VTPptWppydktW+C551QcqlfXx3nnwcMP5ykWlJKiFXF79dKcgt/4JgoiUhtICQhCeaALmjyeAPQBPgP6Ad8EDhkTeD0tsP1XZ/WvjRLM0qW6fOEFfV65Mqxfr0MSi2q2zbv59i74mVm1Sq+nK1b4HD5aswbuuUcv6o0bw48/Qo8e+T9PqVIaZrrmmuC6UHcH9IN88on+EXfuhL/+UpF4/30NP3Xtqp5JqfDR/F9+URGNROgI/PUU6gAfikhpNHfxuXPuOxFZDHwmIk8Dc4F3A/u/C3wsIitRDyFMQV/DKBns3q1ho9q19VpStixMmwaXXKJ3jEWV8uWhalX9bOHwhqomJQVFYfNmjcIcTc+ILOzfryr7wgvanu755/WCXJhFpEQynq9WLX2PUKZMgZdf1vzEffdpjfKPPoJq1bKc7ptv9Iage/fCMzEnfBMF59wCoFWY9auBM8KsPwj09csewyhKeF7CoEF6zbj2WjjtNFi2rOh6CR716sGmTeG37d+vy3Xr9O64dm3YulUjMHXqFOBNndNuRPfcoye/6ip48cXC6zWaXzp00Idz8Prratfpp2tCO1PuYeJE6NgxcsUPbUazYcQgnij07KkTuF58UV8XdUEA7eSWXZ7A8xQWLNDrZcuW+rpAIaRZs3Rq9KWX6i33b7/BiBHRE4RQROAf/1CbkpPh7LMhMTF98/btOgKtU6fImWSiYBgxyNKlWsrghBOgS5dg17LiQF48BW8Wc0KCLo8q2bxggcbbTj8d5s6F117T5TnnHMXJfKZDB40Pli+vAhYohzp5sm42UTCMEs7SpZr/jCt2vRHVU9i8WduJZsbzFLz5GZ6nkGdR2L5dwzFnnqkH//orPPWUJpbvuiu2v9CGDXU0VEqKjjmeNIlJkzRsdPrpkTPDRMEwYpClS+GUU6JthT/Uq6fTAbZsybrNE4XUwPTWU09VjynX8NGkSRoeqlNHwzGHDsFLL6kYPPaYho2KAMkNm3FL8+kcqlobunShwujhnHFGZJspmSgYRoyRkqKDUoqzKICGkPbt05FFHl74yOOYY3LOQbB5s2bhzz5bR/TceafGnubN0wx9dhPQYpSZM+GdCSfySt9ppJ3ZnqdWX8s/qg+PqA0mCoYRY4wapXfKRXXWcm7UravLdes0RPbvfwe3Za6eWrOmlh1asCDTSXbv1uGkp5wCX3wBjz6qXsHLLwdjTkUQL8c8YV51fnlwLJPpwCW/3qlzGyKEiYJhxBBpaVptoVkzuPDCaFvjD56n8MMPeqO/alVw2/79wfkIFSro47zztEbdX3+h/wwapFO7Bw/WDGxion5pRbFsbCY8UZgxA37+vQx/j3uHuMP7tDBfuCSMD5goGEYMMWoULFmiYfBsJrgWeY49Vj/b6NH6es+e4LZ9+4JdxWrV0mXXriAcYd3gN6FJEx2fe/75MHs2fPdd0a35EYaFC3W5ezd88AFUP+sU5JlntNbJgAEREYZi+rMzjKLH/v16E3zaaVq2v7gSF6fCsH27vg4Vhf37g82DPFFoXXsDE+K6csb7t+swnMWL4bPPtL9BMcI59RS6ddPX27apl8R992l47O234eKLfe9naqJgGFHm8GHYsAGefhrWrtVKzIVS0iGGCZ03ltlTaNAAypULiMKIEZROaM6ZbgYPVhuGG/dz0Ww5lwfWr9f5a5deGsyPn3ceOsHtqac0+fLTT9qH9bnnfBMHEwXDiDI336wh8uee04E0f/tbtC3yHy/ZDFk9hYoVoWXTFB7ZdLsWmmvalNFPzufFXbewbHkxmNKdDV7oqHlzHWRQrpxOtwBUGO68Uye4tWypFVYfe8wXO2J4JodhlAymTNGoyGWXwS23RNuayOB5CiefHBSFI0dUFGqW3sWkqpcTP+FneOABePZZ6k3VS9XGjcV3qK6XZD7tNM2b33hjmPkJbdroBLeFC6FKFV/sMFEwjCiye7eW4O/fX7s8lhQ6dFAxbNtW+0SANhBqxGpu+aAn8TtWwDvv6BdDsO1AcnI2JywGJCZq6KxqVU2X5Jgyad7cNzssfGQYUcQbf+/V+CkpXHONDjOtUSPoKRz+ZRIzOYNKyX9qFcCAIEDsi8LIkdCqlQrb9u3aFCe/rF2rTd2ijYmCYUSRzIXfShpVqsCBA5D67odUvawz26nJd4/OyJJYiXVRmD5d/5ZffqkRrz590mva5Zn16zW3FG1MFAwjisyfr6NsCtQroAhTpbLjSR4n7uYb2NfmbNoxnbQTss47qFhRl/v2ae7hww911Fas4DUEeuEFbbIG6uzklbQ0LfvRoEHh25ZfTBQMI4rMm6deQnHok5Bv0tLoMfo2Hudf7L38JpYO/ZFdVE8XgFC8dcnJ2h7hhhuCuYhYwJtzsXChilatWvkTBa+7nImCYZRgUlI0uVgiQ0epqdCvHydPfJtnGcyah99h3+F4IHy1irg4HaKZnKxtjkHndsQK27ZpTqFMGe2lfPHFWrXbq/aaG+vX69JEwTBKKD/+CBdcoBWei3D9tqMjJQWuvhqGD2fljc/wCM+yZ6+kF8ML5ymA5hWSk4OJ6aNqvOMT27frnLI//oA33tDSHHv2aNXT7Ni1SxuurV0bFDjLKRhGCeX++3Xk0Z13Qq9e0bYmghw8CH37amXTl19mx4CHAb2AemWzs6trV7Fi7IrCtm1a0bVFCx1S2rmzhgSzCyEtWKBlwc89Fy6/PCgKxdpTEJEGIjJBRJaIyCIRuTuwPkFEpovIPBGZJSJnBNaLiPxbRFaKyAIRKV6FTQwjwI4dWr7nrru0coFPc5Bijx07tLDPN99oLY97703/7Hv2kCdPYd++2BOFlBS1yavVBCoQTZtq/iMcs2frcd276/PFi7UPUNWqkbE5J/z0FFKB+5xzpwLtgDtEpCkwBHjSOZcAPB54DXA+0DjwuBV400fbDCNqTJumyw4domtHRJk5U2fjzpihg/rvuAMggyh4nkJRCx95SeaaNTOub9EiTB+IAKtXa6XYO+7QxPQ338RG6Ah8FAXn3Gbn3JzA873AEqAe4ADv3qgq4LXw7g185JTpQDURKaED9YzizJQpmjg944xoWxIBnIOhQ1UBnYPff9d4SYBwnkJ24aNwouCcj7bnEU8UQj0FUFFYv15nrWdmzRoNFZ19toaZduyIjdARRCinICINgVbADGAg8KKIbABeAgYHdqsHhI4nSAqsy3yuWwNhp1lbt27102zDKDALFmTtLzxlio5UKQY9YXJmxw7o3VtLP/fsCXPnZmknV7GiXhTzklPILAr794e/4EYab45CZk/Bq0ThFboLZfVqOOEEDRc1a6brSowoiEgl4EtgoHNuD/B34B7nXAPgHuBdb9cwh2e5D3DODXPOtXXOta1du7ZfZhtGgdi+XfvAtGypfWHuu09nuQ4cqJGUYh86mjpVx9r+9BO89po2ialePctuIuot7N6tnkLZstmXDa9YMWNOAWIjhJSTpwDhQ0ieKAC0b6/LEiEKIhKPCsJw59xXgdX9AO/5F4DnRCcBoV9LfYKhJcMoUgwbptfDZ5/V3OrQoSoG//2vDsAptqLgHLz0ksZF4uNVHO66K8fZeVWqBD2F7PIJkNFT8LrSZfbCokF2nkL9+lCtWlZPYd8+7SrqiYL3Wyj2OQUREdQLWOKcGxqyaRNwTuD5eYBXIWQMcH1gFFI7YLdzbrNf9hmGn0ybpmWhBw/WtpM7d2qj+kWLtBTCRRdF20IfSE7WmVsPPKCzt+bM0TKoueCJwr59eRcFr2Wn5yn8+CMMGZL9sX6SXaJZJHyyec0aXXqfoUcPHZp6zjnEBH56Ch2A64DzAsNP54nIBcAtwMsiMh94Fh1pBPADsBpYCbwN3O6jbYbhG86pKJx1lr4W0TtGERWKBx8MUye/qLNiheYLvvxSr85ffJHn8ZWhnkJOeRZvSOquXcGeCp4oDB8Or75awM9wlGzbpnaXL591W4sW6imEJsRXr9al5ynUrq2znxs29N3UPOFbPwXn3GTC5wkA2oTZ3wF3+GWPYUSKVav0QuGJQrEmJQVefFG7wlSsqA1gunTJ1ymqVFFPqly5nD0Fb9uff+rIrVq1gqJw4IDODo8G27dn9RI8mjeHvXt1ctpxx6k4eJ6CJwqxhjXZMYxCZupUXRZ7UVizRstVTJ+ubeNeey1j8+U8UqWKhnxaGOoAACAASURBVNYqVcrdUwAd1FSlir5VqCgcPHgUn6EQ2L49a5LZw7vwr12rVVAvvFB7JlSqlP0x0cZEwTAKmWnT9KLVtGm0LfGRkSPh1ls1JjZyZIa5B/nFCx9VraphtuzwRME7pl49vdBCdD0Fr8RFOI4/Xpdr16qYeY8WLWK3Mq7VPjKMQmbaNG24nt3QyiLNvn1w881w5ZWqevPmFUgQIGOiOS+egndM1aoamgEVhbS0vFclLUxy8hS8Yabr1mlYsVIl7cfdsWPk7Msv5ikYRiGydauONnnyyWhb4gPjxmldhlWr4OGH4Z//1GGnBaRKlWBJ7LzkFLxjKlQITng7cECXhw7pbPFIkpOnUK6cNlBau1Z7Jpx0klb6iGXMUzCMQmTsWE0mnn9+tC0pRObO1Trf3btrzOOXX+CZZwpFECDYdW7jxpyLA4Z6CpUrhxeFSOcVUlN1NFR2ogAaQlq3TkcdnXiifoWxGjoC8xQMo1D58Uctidy6uNT4ffNNnXxWpYpOsLj77kIfT9u/v95Br1ihupMdmcNH2XkKkWTpUr0JOOmk7Pdp2FC9g40btepHrGOiYBiFRFqaegoXXBCccVtkOXxYmz0MG6Yf6JNPwpapKAzi4rT/QOfOOe+XWRTKl1cRSEuLnqcwe7Yu22QZZB/k+OPhs8/0+Ykn+m9TQSnqP13DiBlmzQrWPCrSbNumV+hhw2DQIBgzxjdByA/hcgqgghAtT2H2bLXr5JOz38cbgQRFQxTMUzCMfHLggMaR64QUdv/pJx2UU7681joqsqxcqZ7B+vUwYgRcdVW0LUonXPgINIQUTU8hISHnkWahM5VjdcJaKOYpGEY+efxxHWeekqKvk5K0pWa1atouIKekY0zj1ebYsUOTyTEkCJBxuGqoKOzaFSwjEUlPIS1NR+TmFDqCoKcQFxc7lVBzwkTBMPLJpEkaYZk+XV+/+qp2z/ruOx2DXuRITYXnnoO//U2Vbdq0mCzjWqpUMITkjT6CYEE6iKynsHSpeil5FYWGDSM/XPZoMFEwjHxw+LDeHYImlXft0tD75ZfHTkGzfLF+vYrBww+ruzNtGjRuHG2rsqViRR38VLZseFGIpKeQlyQzqM21ahWNfAJYTsEwMuBczmPIFy0KTpAaO1bvXvfu1WrRRY7Ro+GmmzQOMny41jGKcSpVCoaKou0p/PCD2uNVbM2Jhx8uGvkEME/BMDJwzTX6n/fzz8Nv/+MPXV57rd4pPvecht5btYqcjQXm4EGdmXzppTrAfu7cIiEIoBdhb4JbND2FOXO05NOdd+atnMk99xSNOQpgomCUAF5/XRuajB2b837JydoO4M8/tVfMd99l3WfWLKhRA/7+d71jrVUL/vMff+z2hdmztTDTG29oj9ApU4pOXIPcRSESnoJz2hOjZk146CH/3y/S5EsURCSHyiSGEXv89ptOwv3zT50/8PHHWfe54w79z/3LL5oz+PprbXzyySdZ9/3jD20m1qYN9OunUZciMdooJUXbwJ1xBmzZoor30ktQpky0LcsX550HXbvqc6+pTaQ9hfXr9bfywAN57iNUtHDO5foA2gOLgfWB1y2BN/JyrJ+PNm3aOMPIjsOHnatTx7lTTnHuzz+dS0hwrmXLrPtUqOBcqVLOnXuuc1Wq6LoBA3R9cnJw3/37nYuLc+7hhyP7OQrMokXOdezoHDjXv79zO3dG26JCYcMG/Uh9+ugSnPv3v/1/3x9/1PeaONH/9/ILYJbL5rqaV0/hFaA7sD0gJPOBswtboAyjMNi+XYeIjh+vlSmHDIFjj4UbboD582HZsuC+8+frsMIjR2DCBO2XGx+v4aP9+zOGkKZM0dGbMThaMzxJSVpYqHlzLd06fDi8807OTQuKENHKKSxZostTT/X/vaJBnsNHzrkNmValFbIthlFg/vpLx4U/9pgmi6tWDc4w7ts32BPGY8oUXXp51p49ddmpE/zf/2Xcd9w4FYxYabCeLdOnaya8cWONgd19t5boLCLJ5LziicKOHcF1kcgpLF2qIcNY7ZxWUPI6JHWDiLQHnIiUAe4ClvhnlmEcHW+/rc1aXnpJx7JfemmwqGfdunqxHzlSZyWDts487jhNRjdpol0lQUeUXHSRCsuRIzr0dNw4bY6SU83/qLJnDzz6qGa+q1WDG2/UjGiRnECRO2XLqshHylPYtUu/1qVL8zYMtaiSV09hAHAHUA9IAhICr7NFRBqIyAQRWSIii0Tk7pBtd4rIssD6ISHrB4vIysC2HIroGkZWUlPhrbd0VnF8vM4fyNwU7OqrYfFiFQHn1FPo0EH/sz/xRMZSCu3bw+7dehH4808NNcVkXaNDh7Q/8oknqiDcdZeGjt54o9gKAqggVKgQmdFHf/2lJdG/+ELDR8U1dAR59BScc9uAa/J57lTgPufcHBGpDMwWkZ+BY4HeQAvn3CEROQZARJoCVwKnAXWB8SLSxDlnYSojR3bv1rv6tDStWf/66zpC5M03oUuXjPv27w/ff6/jy1eu1P2zyxGcdZYup00LDtLJqd5/xDlyRGsyP/oorFmjQ3NeeEGHR5UQKlTQbnegEwr98hQ2btQBXC+9pO9X4j0FEflQRKqFvK4uIu/ldIxzbrNzbk7g+V403FQP+DvwvHPuUGDblsAhvYHPnHOHnHNrgJXAGfn9QEbJY+hQrUe0ZYteD3v21Iv+4sVZR1zGxel1tFs3rVkEWuUhHE2a6JyEqVPhq690mGrLlr5+lLzz88/6Ya+5Rgfu//STZtZLkCBARs+uWjX/PAWvF/TMmboszp5CXsNHLZxzu7wXzrmdQJ7ncIpIw8D+M4AmQCcRmSEiv4uIV0KsHhCazE4KrMt8rltFZJaIzNrq3SIYJZYdO+CVVzR3sGKFziPIbYZphQp6Dd2+XctWnHZa+P1EoF07HYH0zTdwyy0x0DxnzhxVtG7dtKnxJ5/oOq9VZgnDE4W4OM31+OUpeKLgUeI9BaCUiKR32RCRGuQx9CQilYAvgYHOuT2B46oD7YAHgM9FRIBwv2iXZYVzw5xzbZ1zbWvXrp1H843iyJ49cNttOhP5ySfzf3yNGtC0ac77nHWWeiDx8ep9RI2kJPUK2rRREXjlFU12XHNNDChV9PBEoXx5KFfOP08hOVmXFSvq+4Q2zilu5HX00cvAVBEZFXjdF3gmt4NEJB4VhOHOua8Cq5OArwITKGaKyBGgVmB9aLXx+sCmPNpnlDB27tTr47p18K9/QbNm/rxP+/a67NdPh6hGhdGjNRly8KDOSn7ooWI6lTb/eLOaPVHIr6ewcaNe6HObuuF5Cs88o95pXuodFVXymmj+SERmAeehd/SXOucW53RM4O7/XWCJc25oyKavA+f5TUSaAGWAbcAYYISIDEUTzY2Bmfn8PEYJ4bPPNLf600/+Jn87ddIKl3fkONbOR155Be69V3MFn36ac4f4Ekiop1C2bP49hQsu0K/23Xdz3s8ThRtuKP56nKMoiEgV59yeQLjoT2BEyLYazrkd2R9NB+A6YKGIBCrQ8zDwHvCeiCQCh4F+Aa9hkYh8jpbTSAXusJFHRnYMH66hH7+HiMbH691hxHEOHnlEy7D26aO5A2/ChZFO5vBRfj2FNWvyNsHbE4WYnaNSiOTmKYwAegKzyRjfl8DrbCuEO+cmEz5PAHBtNsc8Qx7CUkbJZu1anV/wzDPFNLd6+LD2ORg+XLPbb75ZvOMVBSCzp5A5IZwThw7p/ps3575vcrK+R1HonFZQcvyIzrmegTDQOc659RGyyTCycMcdWva/d28tXw3FrmqDsmuXDqWaMEFVb/DgYqp8hUNmT2Hbtrwf6+2bF1HYu1dbgJYEctU955wTkdFALk3nDMMfvv9eJ+fWqweDBum6Sy4phpN1N2zQ+t7Ll2uN72vDOtRGCAXJKXgj2pOT9VGpUvb7liRRyOtYtukh8wkMI2Ls2we33675g9WrtdzA/v06maxYsXChjn/dsEGz5yYIeaIgOYXQaU6bN2vErm1bnZOSmb17cxaN4kReI2TnAgNEZC2wj0BOwTnXwi/DDAN04u769XqdLFNG688UO37/HXr10qvOpEnQwv5b5ZXC8BRAReG773RC48UXa52r0D9DcnLJ8RTyKgrn+2qFYWSD1/ugXbvo2uEbs2drXY4GDVT5jjsu2hYVKcJ5CqmpusxtpFBo/mHJEhWJa67R/P6qVRlFYe9eLXNSEsgxfCQi5URkIDrzuAew0Tm3zntExEKjRLN8uTbIKZZjw1es0IHyNWtq3SIThHwTOnnN8xReeEEnM7os9RAyEuop/P67Lr3JipkT1pZTCPIh0BZYiHoLL/tukWGEsHy5FqYrdqxdC50765Xrp5+02YORb8J5CgsX6te7KZd6CFu3aqOcsmWDouBVxg0nCpZTUJo655oDiMi72AxjI8IsX67h9mLFxo1a5jo5WYeeFufqaj6TOaeQmqplokCLHdbLUlIzyNatGhKqWFHLpZQqpcURK1bMKgolKaeQm6eQ4j1xzqX6bIthZGDXLi1GV6w8hb/+Ug9h2zYYOzaGanEXTTJ7CqBeAqgo5MS2bSoKdero60aNdDBDrVoZRcG5kiUKuXkKLUVkT+C5AOUDr73RR1V8tc4o0SxfrstiIwrbt0PXrjrsdOxYbRFnFIhQUfB6Z2zcqMvExJyP3bpVhzofOaKvvd9ZZlHYv1/3MVEAnHM2t96IGsVKFDZvDk5M+/57bfZsFJhQUchcgiI3T8HLKXgVRLITBa90huUUDCPKLF+ucd4TT4y2JQVk6VLo0UOvNGPGaPjIKBRCRSG0PFSNGioKzoWvEpKWpo5b7drBOoOhorBiRXBfTxRKiqdQcrtzGDHFmjVawiI1JHO1bFkwzltkmTpVm0AfOKBDXPwu61rCqFdPE8NNmmQsItu5s+YB1mdTsW3nThWM0JxCdp6C12DHRMEwIsgTT+j48vnzg+uWLi3ioaNvvtGrU40aMG2adgUyCpWaNfWi3bFjMNEMmrqB8CGk337Ttq2gotC5s85iPvNMXVerlnb1O3xYX5unYBgRZssWGDlSn3uicOgQLF5chAfn/O9/Wu20RQv1Fk7Itsq8UUiEegpduujyt9+y7nfllfqnARWFhg21uZ130a9VS5fbt+uypOUUTBSMqDNsmN6VxccHRSExUUNJrVpF17Z8s20b3HcfDBigieVffy059RGijOcplC2rF/qrroL//jc4b8Fj165gjSRPAELx1nkhJPMUDCOCpKXBW29pqL1Nm6AozJ2ryyIjCosWwc03aw2joUPhttvg669LRquuGMHzFOrU0eTys8/q7+uxx4L7pKSoF3raaXrxD1d+3dPwjRu1/7c3xNVEwTAiwMSJ+p+uf38NFc2frwnAuXP1P2HMjzxKTYWnnlLjR4yAfv1UIN56q2S06YohPE/BSxw3bKg6/dFHwQEM+/bp8uabNWwZrhWn5yl88AE8/ji8/rq+LimiYL9aI6qMGKGx2p49NYb7v/+puz93LiQk6JDUmGX1arjuOs0ZXHstvPqqZj6NqBDqKXicfLJOPNu1Sy/23kiiSpWyb2jnicK33+pyzZrgMSWBWP4vZxRzDh2CUaO0i1qFCsGk8ty56jHEbOjIOfjwQ1WtRYtU2T7+2AQhynieQmhtwerVdblzpy5DRSE7atTQ5f79Gc9dUhw/30RBRBqIyAQRWSIii0Tk7kzb7xcRJyK1Aq9FRP4tIitFZIGItPbLNiP6bNqk7Yd37Qr2Wm7eXJfDhul/yJgUhZ074Yor4IYb1MD58zWjaUSdcJ6CJwo7dugyL6IQHx8MK/XurcuSEjoCf8NHqcB9zrk5IlIZmC0iPzvnFotIA6ArEDq15HygceBxJvBmYGkUMw4c0Ovpli1aAdWb4Fu5siYAv/9eX58Za3/9mTOhTx8tWfHcc/DAAxmn0RpR5dhjtT1F6PxA764/s6eQW/6/Vi29YXn0UZ1zaKJQCDjnNgObA8/3isgSoB6wGHgFeBAI7YbaG/jIOefQntDVRKRO4DxGMWLsWBWEb77JWhb79981VF+hApx6anTsC8t778Hf/66xiWnTtJmvEVPExwdvKDyOJnwEQVFo3VrHDngjkEoCEYmSiUhDoBUwQ0R6oR3c5kvGTE89YEPI66TAugyiICK3ArcCHGedqookX36pd3Dnh2nyWrNmjIXmDx+GgQPhzTd1muynn8aYgUZOHE34COCWW9SjLVVKxw+UJHwXBRGpBHwJDERDSo8A4QrAhBsLkKWhnnNuGDAMoG3btrk03DNiiZUr9T/pmDEahYmPj7ZFubBpkxo6bZqGip59tuRkG4sJR+sp3HSTfzbFOr7+wkUkHhWE4c65r0SkOdAI8LyE+sAcETkD9QwahBxeH8iloZ5RVNi2TfMFcXGaRO7TJ9oW5cLkydC3r05n/fxzfW4UOcqW1VBkfkWhJOPn6CMB3gWWOOeGAjjnFjrnjnHONXTONUSFoLVz7k9gDHB9YBRSO2C35ROKD7/9ppGYU07RR8xWj3ZOayOce65mF2fMMEEo4lSvHhQFb/KaTTTPHj89hQ7AdcBCEZkXWPewc+6HbPb/AbgAWAnsB2700TYjwkyYoP8Rp0+P4bDR/v1as+jjj3U23ccfh5/yahQpatTImFMoU6aIl2P3GT9HH00mfJ4gdJ+GIc8dcIdf9hjR5ddf4eyzY1gQNm5UIZg/H558UscixvR0aiOvhHoKyckWOsoNy5oZvrNpk/ZG6N8/2pZkw7p1cN55Ok7222/hwgujbZFRiFSvrsOcwUQhL9itkFEouBzGgU2YoMvzzouMLfli5Up1YXbsgPHjTRCKITVqmKeQH0wUjAKzZg1UqQLt2+tw/kOHgtu2btXyw8ccE4MNc+bNU0HYt0/jWzE3hdooDKpXz5hTMFHIGRMFo8BMmaL/2bZvh9tv18qUkyerIPToodGZUaNirCLERx/BWWdp3uC332K00JJRGFSvrmMIDh82UcgLJgpGgUlM1ARyYiKMG6djw7t21UoQixfDV19Bp07RtjLAoUNwxx1au+Css2DOHGjWLNpWGT4SOoHNRCF3TBSMArNwodYpio9XMZgyRatKHzyo+YRw5SwizsGD2gmteXN44w148EFVsGOOibZlhs+EFsUzUcgdG31kFJjEROjYMfi6Vi0VhkOHoHz56NkFBCuavvee5g4aN1Yx6No1yoYZkSK0/lFysk1cyw0TBaNA7NkD69dnjcCUKhUlQdi3T8fAbtyoJTNff12DyddeC5dfDl262MylEoaFj/KHiYJRIBYt0mXUwvIbNmgWe8wYNWbr1uC2UqVUDB5/vAg0ezb8wgsf7dih9wwmCjljomAUiMREXUZMFDZv1qql06fDxIlamwh0vOvFF8MJJ0C9evpo0gTq14+QYUas4nkKGzfqfBoThZwxUTAKRGKixmiPP97HN0lNVU/gzTd1ghloCKh1a3jmGS1Y17ixjwYYRRmvfNX6QJ9HE4WcMVEwCsQff6iX4EuZoNRUeOcdePppvc2rX1/rEnXvrsObvKa8hpEDcXH605k9W1+bKOSMiYJx1GzYoJGcf/2rkE/snHoGDz0Ey5bp0KY33tAGvNbkxjgKzjwTRo/W5yYKOWPzFIyj5vPPdXnllYV40hUrdBr0xRfr66+/1txBr14mCMZRc+aZcOSIPjdRyBkTBeOo+ewznbV80kmFcLKDBzU01Ly5uh+vvqqz4nr3BsmxArth5EpoWSsThZyxWy8jTwwZAmPHahh/xAhtrzlrFrz0UgFP7Bz8+CPcfbdWLL3iChg6FOrWLRS7DQOgTRutvZWWZqKQGyYKRq44p3mDqlU13/vhh/Dnn5pcPurQkXMa5H30UViyRN0Nm2ls+ETFiuqEzptnopAbFj4ycmX9ep0J+uij6oa/9ZZWjejZU6cD5Jt58/Tgyy7T27cPPtCxrSYIho94ISQThZwxT8HIQmoq7NqlNYwg46zlW26Bm2/W17fdlscTOqflUsePhy+/hEmT1O148UUYONASyEZEuPZaSEoKznA2wmP/G40MTJwIf/+7egdJSXrt9mYtn3aaTg+45x6dJdq9e+CglBRtUjNtmroUjRqpEGzZoqGhSZPgr79032bN4Nln9U28WUWGEQE6doTvvou2FbGPb6IgIg2Aj4D/A44Aw5xzr4nIi8BFwGFgFXCjc25X4JjBQH8gDbjLOTfWL/uKC0OGaE2Xu++GOnUKdq5Dh3QqQOnSem2fP18bkyUmat7XKxfw8cdQK2Uzpb+eqt10Ro7U8hMimok+eFB3LFVKpzp36QLnnquPE04omJGGYfiKn55CKnCfc26OiFQGZovIz8DPwGDnXKqIvAAMBh4SkabAlcBpQF1gvIg0cc6l+WhjkcZLACcn69yuJUsyxvgPHoT334err9Y7/tyYP18Lhv3nP3DnncFulYsWQbcTVsIb42DqVHpPnao9OEFFoHNnLUFx3nma0duyRZWlalWrSGoYRQzfEs3Ouc3OuTmB53uBJUA959w451xqYLfpgFexrDfwmXPukHNuDbASOMMv+4oDmzerIFx/Pezdq4N3QnntNW2POXhw3s43a5YuL7pIe8/Mmwdp8xMZNO9K3p3cRDuW/fqrju8bOlSL0u3ZoyWqe/eGypXVO/i//4PatU0QDKMIEpHRRyLSEGgFzMi06Sbgx8DzesCGkG1JgXVGNixbpstrr9Wk8MSJwW179mhoqWxZ+N//1AvIjHP68PjjD72WH3ccXHrifK4e3YfSCc3pceR7Fl44CFav1jGpX3yhiYUzz7QLv2EUM3wXBRGpBHwJDHTO7QlZ/wgaYhrurQpzuMu8QkRuFZFZIjJra2jt/BLI0qW6POUU7YE87ffDWiZi9mxeevYwO3bAt99qLuDBB7MeP3SoHutFgmb94bjmpBnIJRfz5rQETt/1M4mXPsbxrOPQ489qAtlmFxtGscbX0UciEo8KwnDn3Fch6/sBPYHOzqXfqyYBDUIOrw9synxO59wwYBhA27Zts4hGSWLZMqhQ3lFvRyIP7/qYRmvehSY7ALiXqvSs35kzZp/OS+efzhOfNGbrwjLUrlcG9uzBLV3G/ueX0W/bn4xrlcbV7dfy3aLpHM96qFaNBX2e5OxRd1Hlj2qU/T9o0SLKH9YwjIggzvlzXRURAT4EdjjnBoas7wEMBc5xzm0NWX8aMALNI9QFfgEa55Robtu2rZvlBcJLEs7B/Pl8dtkXtNs4ioaHluNKl2ZU2iVMr9WTpG3leLDlWFonT0RWrcrxVGkSR6orxaZS9Zl7pCUn3NmThH9dxpJNVWnaVPd591246aYIfC7DMCKCiMx2zrUNt81PT6EDcB2wUETmBdY9DPwbKAv8rLrBdOfcAOfcIhH5HFiMhpXusJFHITgHc+Zo68lRo2DlSvpQmiXHngtP3suRXpfQ/+Rj2LtNw0Jt7rlCj9uxA/fHLB7tt4Ha1VLo1O4wm3aUZ3utk3no/ZOZu+EYVq8RunWDAwdg02CgKjSpBBUqwMknQ79+Uf3khmFEEN9EwTk3mfB5gh9yOOYZ4Bm/bCqSrFgBb7+tQrBmjc7+7dyZlHsfou7tF3PHgFo0vw1Ko71oAO66K+T4GjWQ7t1wN8G9z4MLJKfj4qBtO6hbTx8//aQDi7y5DqVLwzff6LSC0qUj+YENw4gmNqM5FnEOpk7VYUMjRugwzy5d4LHHtK9AzZosXQjb0Dt5jwxikIkrroAXXoA+faBpU61S3adPcPvZZ+sjlC5dCvVTGYZRBDBRiCU2boSPPtICccuX60SwO++EQYPg2GMz7OqNPAoVhZxo2VIdjfr1VWMuvlirRhqGYYRiohBtVq/WbjVjx2rJiCNH9JZ98GC9lc+mpOPnn2thLy8ZnBeOOy74PCGhgHYbhlEsMVGIFosWaQ/i77/X161bwyOPaFb3xBNzPHTjRm1FcM89UK5cBGw1DKPEYKIQSXbs0ITxiBE6/bhKFQ3u33gjNGiQ+/EB3n5bHYoBA3y01TCMEomJgt94SePXX1dBSEnRRMCTT2phopo183W6adO0plGPHrk6FIZhGPnGRMEv1q9XEfjoIy08VLWqikC/fhrQz0e5COfguus097xwoSaL//MfH203DKPEYu04M7FwYcYicfkiNRWGD4f27bWPwH336SD///2PZb9upOWEV7ngkVZ8NTp/9YNWrtTTpqbq0NJp08xLMAzDH8xTCGHqVOjQQbszXXhhHg5ITtYONAsXwsyZ8MMPsGkTnHoqPPMMXH65NqQHnr5OL+6bNmkTsksvzbtdv/6qy5EjoXHj/H8uwzCMvGKiEMLPP+tywoRMovDnn1pudO5c7VF56JDONPbKi4KGh7p00TjPRRfpZIAA69bBp59qd7S9e2HMmPzZ9csvGjIK6IthGIZvmCiE8Ntvupw8ycHsOcFRQrNna0ypalUtH12mDJx+uo4aat5cH40aZRAC0MFGQ4ZouEdEe9S//756CocP560VwZEjKlIXXGBVqw3D8B8ThQAHD8KKadu4t/Rw+s18D9ou0A417drBE0/AZZdp5/p8XJk/+EBLS1SrpoLQoEGwXebmzZp2yI3ERNi2TTtdGoZh+E2JF4XD+1L449mfOWnie6w+NIYypDCT01k+8A2aPH5lsFt9DmzapAXlMpeXHjdO0wuLFwfX1Q80H01KyioKaWla1K5mTe1u2aCBho5Ae94bhmH4TckcfZSaqlfbW28l9Zg6dHj2QkpNnsjr/IOkHxbQTmYyssbf8yQIAO+8A/37w4aQZqIHD8Lvv0O3bhn39TyFjRuznmfKFPjnP7XcUdu2eo7vv9fuaKElKgzDMPyiZIrCRx9Bly4cGfEp3x3uzsCGX3Ni2SRGtB1K/fOb06yZliHKK2vX6nLRouC6yZP1op5ZFEI9hcx8+y3Ex8OHH8KWLTra6PfftTCqYRhGJCiZm2f+6wAAC65JREFUotC7N6mfjeLW3lu42g1nwI+9mbuoDF98oZs7ddLhqampeTtdOFEYO1Yv8Oeck3HfqlW1eU04T2HMGA0TXX011K4N99+vNlx0Ub4/oWEYxlFRIkVhyZaanPXSZbw7ojwPPKDhmRNPhIYNdXvHjjoFYeHCvJ3PE4XExOC6n3/W81SsmHFfEfUWkpLg0Ud1Mhpov+Xly9UriIuDvn01wVyzJpx1VkE+rWEYRt4pkaKwcaNeyD//HJ57Luv2jh11mZcQUlpaMJfgeQp79sCCBVm9BI969VQU3nlHbZgxIzh3oWdPXV51lS4vvNA6nxmGETlK5OijLl103lk2rQpo0EATu5Mna9I3JzZt0hBPlSoqCkeO6ORm57K/w69fX1sopKTo64cegnnzVIy8EUnt2+v6q68+us9oGIZxNJRITwGyFwSPjh1VFHKrg+SFjrp3h/37dfby9Om67owzwh9Tr15QEK69VpPJpUpp/tujVCl4/nlo0SLXj2IYhlFolFhRyI2OHdUL8C762eFt98piLFqkM5ibNtVJa+HwRiCddprOeG7fXidPN2pUGJYbhmEcPb6Jgog0EJEJIrJERBaJyN2B9TVE5GcRWRFYVg+sFxH5t4isFJEFItLaL9vyghf6mTkz67bx42HnTn3uiUKPHrqcN089hZySw95chW7doE4dnZ/gHW8YhhFN/PQUUoH7nHOnAu2AO0SkKTAI+MU51xj4JfAa4HygceBxK/Cmj7blinfXnnno6KZN0LUrXH+9hpbWrtUL+7HHajmkf/1Lax61a5f9uZs10+Gq+amUahiGEQl8EwXn3Gbn3JzA873AEqAe0Bv4MLDbh8DFgee9gY+cMh2oJiJ1/LIvN6pUgfLlVQRCmTRJl999B19+qaLgDWX99lto0kSft2+f/blPOklHKHmjnAzDMGKFiIw+EpGGQCtgBnCsc24zqHCIyDGB3eoBIYUiSAqs25zpXLeingTH+Vj7QUQ9gM2bM66fOFHnHpx8Mtxyi4428vIJxx6r2+fM0ZxCTpQr54/dhmEYBcH3RLOIVAK+BAY65/bktGuYdVnG/jjnhjnn2jrn2tauXbuwzAxL3brhPYUOHbQExRln6B1/qABUrw6dO/tqlmEYhm/46imISDwqCMOdc18FVv8lInUCXkIdYEtgfRLQIOTw+kCmS3JkqVNHJ6F57Nihs5yvuEJDQGPHwurVKh6GYRjFAT9HHwnwLrDEOTc0ZNMYoF/geT/gm5D11wdGIbUDdnthpmhRp05GT8Gb4dypU3DdCSdYKMgwjOKDn55CB+A6YKGIzAusexh4HvhcRPoD64G+gW0/ABcAK4H9wI0+2pYn6tbV9pnJyTrZ7YcftO9OdpPSDMMwijq+iYJzbjLh8wQAWaLuzjkH3OGXPUdDncDYp82bVQzef1+HoppnYBhGcaVE1j7KK16uYPPmYAmKxx6Lnj2GYRh+Y2UucsDzFObO1X7Lt91mHdAMwyjemCjkgCcK776rJbL794+uPYZhGH5jopAD1atrLmHhQq1XZBVLDcMo7pgo5IA3qxngggv0tWEYRnHGRCEXQkXBMAyjuGOikAt162pFUytdYRhGScCGpObCP/6h7TsrV462JYZhGP5jopALf/ubPgzDMEoCFj4yDMMw0jFRMAzDMNIxUTAMwzDSMVEwDMMw0jFRMAzDMNIxUTAMwzDSMVEwDMMw0jFRMAzDMNIRbXhWNBGRrcC6ozy8FrCtEM0pTGLVNrMrf8SqXRC7tpld+eNo7TreOVc73IYiLQoFQURmOefaRtuOcMSqbWZX/ohVuyB2bTO78ocfdln4yDAMw0jHRMEwDMNIpySLwrBoG5ADsWqb2ZU/YtUuiF3bzK78Ueh2ldicgmEYhpGVkuwpGIZhGJkwUTAMwzDSKZGiICI9RGSZiKwUkUFRtKOBiEwQkSUiskhE7g6s/6eIbBSReYFHxDtEi8haEVkYeP9ZgXU1RORnEVkRWFaPgl0nh3wv80Rkj4gMjMZ3JiLvicgWEUkMWRf2OxLl34Hf3AIRaR1hu14UkaWB9x4tItUC6xuKyIGQ7+2tCNuV7d9NRAYHvq9lItLdL7tysG1kiF1rRWReYH0kv7PsrhH+/c6ccyXqAZQGVgEnAGWA+UDTKNlSB2gdeF4ZWA40Bf4J3B/l72ktUCvTuiHAoMDzQcALMfC3/BM4PhrfGXA20BpIzO07Ai4AfgQEaAfMiLBd3YC4wPMXQuxqGLpfFL6vsH+3wP+D+UBZoFHg/2zpSNqWafvLwONR+M6yu0b49jsriZ7CGcBK59xq59xh4DOgdzQMcc5tds7NCTzfCywB6kXDljzSG/gw8PxD4OIo2gLQGVjlnDvaWe0Fwjk3EdiRaXV231Fv4COnTAeqiUidSNnlnBvnnEsNvJwO1PfjvfNrVw70Bj5zzh1yzq0BVqL/dyNum4gIcDnwqV/vnx05XCN8+52VRFGoB2wIeZ1EDFyIRaQh0AqYEVj1j4D79140wjSAA8aJyGwRuTWw7ljn3GbQHytwTBTsCuVKMv5HjfZ3Btl/R7H0u7sJvZv0aCQic0XkdxHpFAV7wv3dYun76gT85ZxbEbIu4t9ZpmuEb7+zkigKEmZdVMflikgl4EtgoHNuD/AmcCKQAGxGXddI08E51xo4H7hDRM6Ogg3ZIiJlgF7AF4FVsfCd5URM/O5E5BEgFRgeWLUZOM451wq4FxghIlUiaFJ2f7eY+L4CXEXGm4+If2dhrhHZ7hpmXb6+t5IoCklAg5DX9YFNUbIFEYlH/9jDnXNfATjn/nLOpTnnjgBv46PbnB3OuU2B5RZgdMCGvzxXNLDcEmm7QjgfmOOc+wti4zsLkN13FPXfnYj0A3oC17hAADoQntkeeD4bjd03iZRNOfzdov59AYhIHHApMNJbF+nvLNw1Ah9/ZyVRFP4AGotIo8Dd5pXAmGgYEohVvgsscc4NDVkfGgO8BEjMfKzPdlUUkcreczRJmYh+T/0Cu/UDvomkXZnIcPcW7e8shOy+ozHA9YHRIe2A3Z77HwlEpAfwENDLObc/ZH1tESkdeH4C0BhYHUG7svu7jQGuFJGyItIoYNfMSNkVQhdgqXMuyVsRye8su2sEfv7OIpFBj7UHmqFfjir8I1G0oyPq2i0A5gUeFwAfAwsD68cAdSJs1wnoyI/5wCLvOwJqAr8AKwLLGlH63ioA24GqIesi/p2horQZSEHv0Ppn9x2hbv3rgd/cQqBthO1aicaavd/ZW4F9Lwv8jecDc4CLImxXtn834JHA97UMOD/Sf8vA+g+AAZn2jeR3lt01wrffmZW5MAzDMNIpieEjwzAMIxtMFAzDMIx0TBQMwzCMdEwUDMMwjHRMFAzDMIx04qJtgGEUFUQkDR3mF4/OCv4QeNXpxCvDKBaYKBhG3jngnEsAEJFjgBFAVeCJqFplGIWIhY8M4yhwWv7jVrSYmwRq7E8SkTmBR3sAEflYRNKr8IrIcBHpJSKnicjMQD3+BSLSOFqfxTBCsclrhpFHRCTZOVcp07qdwCnAXuCIc+5g4AL/qXOurYicA9zjnLtYRKqiM1IbA68A051zwwPlVko75w5E9hMZRlYsfGQYBcOrShkP/FdEEoA0AgXSnHO/i8jrgXDTpcCXzrlUEZkGPCIi9YGvXMayzIYRNSx8ZBhHSaAYWhpaofIe4C+gJdAW7ern8TFwDXAj8D6Ac24EWvr7ADBWRM6LnOWGkT0mCoZxFIhIbeAt4L9OY7BVgc2BkUjXoa1CPT4ABgI45xYFjj8BWO2c+zdaCK5F5Kw3jOyx8JFh5J3yos3bvSGpHwNeOeM3gC9FpC8wAdjnHeSc+0tElgBfh5zrCuBaEUlB+0w/FQH7DSNXLNFsGD4jIhXQ+Q2tnXO7o22PYeSEhY8Mw0dEpAuwFPiPCYJRFDBPwTAMw0jHPAXDMAwjHRMFwzAMIx0TBcMwDCMdEwXDMAwjHRMFwzAMI53/ByhhXh+5ZoIvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data):\n",
    "    y_test = data[\"y_test\"]\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    y_pred = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_pred[LOOKUP_STEP:]))\n",
    "    y_test = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_test[LOOKUP_STEP:]))\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 : Accuracy Score: 0.6069394096323149\n"
     ]
    }
   ],
   "source": [
    "print(LOOKUP_STEP , \":\", \"Accuracy Score:\", get_accuracy(model, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
